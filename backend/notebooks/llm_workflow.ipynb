{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiGen Agent Workflow Testing\n",
    "\n",
    "This notebook provides an environment to test the WikiGen agent-based story processing workflow using the new **BaseAgent architecture**. Each agent can be tested individually with different LLM models to demonstrate the flexibility and modularity of the system.\n",
    "\n",
    "## 🏗️ BaseAgent Architecture\n",
    "\n",
    "All WikiGen agents now inherit from `BaseAgent`, providing:\n",
    "- **Default Models**: Each agent has configurable default provider/model\n",
    "- **Override Flexibility**: Can override provider/model per call when needed  \n",
    "- **Centralized LLM Logic**: Common error handling and validation\n",
    "- **Clean API**: Simplified method signatures with optional parameters\n",
    "\n",
    "## 📋 WikiGen Agents\n",
    "\n",
    "1. **ArcSplitter Agent** - Analyzes story structure and determines arc boundaries\n",
    "2. **WikiPlanner Agent** - Plans wiki structure and article organization  \n",
    "3. **ArticleWriter Agent** - Generates actual wiki article content\n",
    "4. **GeneralSummarizer Agent** - Creates summaries of various content types\n",
    "5. **ChapterBacklinker Agent** - Creates bidirectional links between chapters and articles\n",
    "6. **WikiGenOrchestrator** - Coordinates the complete workflow\n",
    "\n",
    "Each agent demonstrates the BaseAgent pattern with different default models to show architectural flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ Setup\n",
    "\n",
    "Make sure the Portkey Gateway is running to use the LLM Service:\n",
    "\n",
    "```bash\n",
    "docker run \\\n",
    "  --name portkey-gateway \\\n",
    "  -p 8787:8787 \\\n",
    "  portkeyai/gateway:latest\n",
    "```\n",
    "\n",
    "The following cells will:\n",
    "- use the Portkey Gateway to test the LLM Service\n",
    "- initialize the LLM Service\n",
    "- import the WikiGen workflow agents\n",
    "- load a test story from the `tests/resources/pokemon_amber/story` directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 LLM Service Testing Notebook\n",
      "==================================================\n",
      "Current working directory: /home/jimnix/gitrepos/shuscribe/backend/notebooks\n",
      "Database mode: IN-MEMORY\n",
      "Portkey Gateway: http://localhost:8787/v1\n",
      "Autoreload enabled. Changes to .py files in src/ will be reloaded.\n",
      "\n",
      "💡 This notebook tests LLM service functionality without requiring database setup.\n",
      "   Perfect for testing direct API key usage and LLM provider integrations.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Configuration for LLM Service Testing\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import logging\n",
    "from uuid import uuid4\n",
    "\n",
    "# Set environment to skip database for LLM service testing\n",
    "os.environ[\"SKIP_DATABASE\"] = \"true\"\n",
    "os.environ[\"PORTKEY_BASE_URL\"] = \"http://localhost:8787/v1\"  # Default Portkey Gateway\n",
    "\n",
    "# Add the backend/src directory to sys.path so we can import our modules\n",
    "# This assumes you are running the notebook from the `backend/` directory or VS Code multi-root\n",
    "notebook_dir = Path.cwd()\n",
    "if (notebook_dir / 'src').is_dir() and (notebook_dir / 'pyproject.toml').is_file():\n",
    "    # This means we're likely in the backend/ directory itself\n",
    "    sys.path.insert(0, str(notebook_dir / 'src'))\n",
    "elif (notebook_dir.parent / 'src').is_dir() and (notebook_dir.parent / 'pyproject.toml').is_file():\n",
    "    # This means we're likely in the backend/notebooks/ directory\n",
    "    sys.path.insert(0, str(notebook_dir.parent / 'src'))\n",
    "else:\n",
    "    print(\"Warning: Could not automatically add 'src/' to Python path. Please ensure your current directory allows imports from src/\")\n",
    "\n",
    "# Configure logging for better output\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "# Reduce noise from third-party loggers\n",
    "logging.getLogger('httpx').setLevel(logging.WARNING)\n",
    "logging.getLogger('uvicorn.access').setLevel(logging.WARNING)\n",
    "logging.getLogger('shuscribe').setLevel(logging.INFO)\n",
    "\n",
    "print(\"🧪 LLM Service Testing Notebook\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Database mode: {'IN-MEMORY' if os.environ.get('SKIP_DATABASE') == 'true' else 'SUPABASE'}\")\n",
    "print(f\"Portkey Gateway: {os.environ.get('PORTKEY_BASE_URL', 'Not configured')}\")\n",
    "print(\"Autoreload enabled. Changes to .py files in src/ will be reloaded.\")\n",
    "print(\"\\n💡 This notebook tests LLM service functionality without requiring database setup.\")\n",
    "print(\"   Perfect for testing direct API key usage and LLM provider integrations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-02 22:43:35,117 - src.config - INFO - Pydantic Settings 'extra' mode set to: 'ignore' for environment: 'development'\n",
      "✅ Modules imported successfully.\n",
      "\n",
      "--- Current Settings ---\n",
      "DEBUG: True\n",
      "ENVIRONMENT: development\n",
      "DATABASE_BACKEND: memory\n",
      "PORTKEY_BASE_URL: http://localhost:8787/v1\n",
      "DATABASE_MODE: In-Memory (Supabase skipped)\n",
      "------------------------\n",
      "\n",
      "🔧 Import Summary:\n",
      "✅ LLMService - Ready for testing\n",
      "✅ Repository Factory - Automatic in-memory/Supabase switching\n",
      "✅ Pydantic Models - Type-safe user schemas\n",
      "✅ Encryption - API key encryption/decryption\n",
      "✅ Supabase Connection - Available when SKIP_DATABASE=false\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Modules (Updated for Supabase)\n",
    "from src.config import settings\n",
    "from src.services.llm.llm_service import LLMService\n",
    "from src.api.dependencies import get_user_repository_dependency\n",
    "from src.schemas.llm.models import LLMMessage, LLMResponse\n",
    "from src.core.encryption import encrypt_api_key  # Import encryption function\n",
    "from dotenv import dotenv_values\n",
    "from src.schemas.db.user import UserCreate, UserAPIKeyCreate\n",
    "\n",
    "print(\"✅ Modules imported successfully.\")\n",
    "\n",
    "# Display current settings\n",
    "print(\"\\n--- Current Settings ---\")\n",
    "print(f\"DEBUG: {settings.DEBUG}\")\n",
    "print(f\"ENVIRONMENT: {settings.ENVIRONMENT}\")\n",
    "print(f\"DATABASE_BACKEND: {settings.DATABASE_BACKEND}\")\n",
    "print(f\"PORTKEY_BASE_URL: {settings.PORTKEY_BASE_URL}\")\n",
    "if settings.DATABASE_BACKEND == \"postgres\":\n",
    "    print(f\"SUPABASE_URL: {settings.SUPABASE_URL}\")\n",
    "    print(f\"SUPABASE_KEY: {'***' + settings.SUPABASE_KEY[-4:] if len(settings.SUPABASE_KEY) > 4 else 'Not set'}\")\n",
    "else:\n",
    "    print(\"DATABASE_MODE: In-Memory (Supabase skipped)\")\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"\\n🔧 Import Summary:\")\n",
    "print(\"✅ LLMService - Ready for testing\")\n",
    "print(\"✅ Repository Factory - Automatic in-memory/Supabase switching\") \n",
    "print(\"✅ Pydantic Models - Type-safe user schemas\")\n",
    "print(\"✅ Encryption - API key encryption/decryption\")  # Updated\n",
    "print(\"✅ Supabase Connection - Available when SKIP_DATABASE=false\")\n",
    "\n",
    "# WikiGen agent imports\n",
    "from src.agents.wikigen import (\n",
    "    WikiGenOrchestrator,\n",
    "    ArcSplitterAgent,\n",
    "    WikiPlannerAgent,\n",
    "    ArticleWriterAgent,\n",
    "    GeneralSummarizerAgent,\n",
    "    ChapterBacklinkerAgent\n",
    ")\n",
    "\n",
    "from src.schemas.llm.models import ThinkingEffort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Initializing LLM Service...\n",
      "✅ LLM Service initialized successfully!\n",
      "📁 Repository type: MemoryUserRepository\n",
      "🛡️  Database mode: memory\n",
      "   🔐 Stored and encrypted OpenAI API key\n",
      "   🔐 Stored and encrypted Google API key\n",
      "   🔐 Stored and encrypted Anthropic API key\n",
      "✅ Stored 3 encrypted API keys\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize LLM Service (UPDATED)\n",
    "\n",
    "print(\"🚀 Initializing LLM Service...\")\n",
    "\n",
    "# Use the dependency function to get user repository\n",
    "from src.api.dependencies import get_user_repository_dependency\n",
    "\n",
    "llm_service = LLMService(user_repository=get_user_repository_dependency())\n",
    "\n",
    "print(\"✅ LLM Service initialized successfully!\")\n",
    "print(f\"📁 Repository type: {type(llm_service.user_repository).__name__}\")\n",
    "print(f\"🛡️  Database mode: {settings.DATABASE_BACKEND}\")\n",
    "\n",
    "assert llm_service.user_repository is not None\n",
    "\n",
    "# Create test user and store API keys (following test patterns)\n",
    "TEST_USER = await llm_service.user_repository.create_user(UserCreate(\n",
    "    email=\"test@example.com\",\n",
    "    display_name=\"Test User\"\n",
    "))\n",
    "\n",
    "# Store API keys from environment (following test service patterns)\n",
    "env_values = dotenv_values()\n",
    "stored_keys = 0\n",
    "available_providers = []\n",
    "\n",
    "for provider in LLMService.get_all_llm_providers():\n",
    "    provider_id = provider.provider_id\n",
    "    api_key = env_values.get(f\"{provider_id.upper()}_API_KEY\")\n",
    "    \n",
    "    if api_key:\n",
    "        # Properly encrypt and store the API key\n",
    "        encrypted_key = encrypt_api_key(api_key)\n",
    "        await llm_service.user_repository.store_api_key(\n",
    "            user_id=TEST_USER.id,\n",
    "            api_key_data=UserAPIKeyCreate(\n",
    "                provider=provider_id,\n",
    "                api_key=api_key,\n",
    "                provider_metadata={}\n",
    "            ),\n",
    "            encrypted_key=encrypted_key\n",
    "        )\n",
    "        stored_keys += 1\n",
    "        available_providers.append(provider.display_name)\n",
    "        print(f\"   🔐 Stored and encrypted {provider.display_name} API key\")\n",
    "\n",
    "print(f\"✅ Stored {stored_keys} encrypted API keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�� Loading Test Story with Flexible Dependency Injection...\n",
      "�� Using repositories:\n",
      "   �� Story: MemoryStoryRepository\n",
      "   📁 Workspace: MemoryWorkspaceRepository\n",
      "   👤 User: MemoryUserRepository\n",
      "✅ Pokemon Amber story loaded successfully!\n",
      "\n",
      "�� Story: Pokemon: Ambertwo\n",
      "✍️  Author: ChronicImmortality\n",
      "�� Chapters: 8\n",
      "�� Words: 19,378\n",
      "📁 Workspace: 17c1b055-ea8a-4220-bdc7-159ac158dd7f\n",
      "👤 User: 6b631c84-c6b5-497d-b4a9-a39fbf3c6bd7\n",
      "\n",
      "🎯 Ready for agent testing!\n",
      "   📖 STORY: Pokemon: Ambertwo (8 chapters)\n",
      "   📁 WORKSPACE_ID: 17c1b055-ea8a-4220-bdc7-159ac158dd7f\n",
      "   👤 USER_ID: 170ba109-1a06-44c8-9388-dd6c356aecd5\n",
      "   🔑 Repository types: MemoryStoryRepository\n",
      "\n",
      "🔑 User verification:\n",
      "   �� Current user ID: 170ba109-1a06-44c8-9388-dd6c356aecd5\n",
      "   👤 Cell 3 user ID: 170ba109-1a06-44c8-9388-dd6c356aecd5\n",
      "   ✅ Same user: True\n",
      "\n",
      "💡 Example: Load any story directory with _meta.xml format:\n",
      "   story_result = await load_story_with_repositories(\n",
      "       story_directory=Path('/path/to/your/story'),\n",
      "       story_repository=story_repo,\n",
      "       workspace_repository=workspace_repo,\n",
      "       user_repository=user_repo,\n",
      "       workspace_name='Custom Workspace',\n",
      "       user_email='test@example.com'  # Use same user as Cell 3\n",
      "   )\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load Test Story with Flexible Dependency Injection\n",
    "\n",
    "print(\"�� Loading Test Story with Flexible Dependency Injection...\")\n",
    "\n",
    "# Import the flexible story loader with dependency injection\n",
    "from src.utils.test.import_story import (\n",
    "    load_pokemon_amber_with_repositories,\n",
    "    create_test_story_with_repositories,\n",
    "    load_story_with_repositories\n",
    ")\n",
    "from src.api.dependencies import (\n",
    "    get_story_repository_dependency,\n",
    "    get_workspace_repository_dependency, \n",
    "    get_user_repository_dependency\n",
    ")\n",
    "from src.schemas.db.story import FullStoryBase\n",
    "\n",
    "# Get repositories using dependency injection (can be any implementation)\n",
    "story_repo = get_story_repository_dependency()\n",
    "workspace_repo = get_workspace_repository_dependency()\n",
    "user_repo = get_user_repository_dependency()\n",
    "\n",
    "print(f\"�� Using repositories:\")\n",
    "print(f\"   �� Story: {type(story_repo).__name__}\")\n",
    "print(f\"   📁 Workspace: {type(workspace_repo).__name__}\")\n",
    "print(f\"   👤 User: {type(user_repo).__name__}\")\n",
    "\n",
    "try:\n",
    "    # Try to load Pokemon Amber story with injected repositories\n",
    "    # Use the same user that has API keys from Cell 3\n",
    "    story_result = await load_pokemon_amber_with_repositories(\n",
    "        story_repository=story_repo,\n",
    "        workspace_repository=workspace_repo,\n",
    "        user_repository=user_repo\n",
    "    )\n",
    "    print(\"✅ Pokemon Amber story loaded successfully!\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"⚠️  Pokemon Amber story not found: {e}\")\n",
    "    print(\"📝 Creating minimal test story instead...\")\n",
    "    story_result = await create_test_story_with_repositories(\n",
    "        story_repository=story_repo,\n",
    "        workspace_repository=workspace_repo,\n",
    "        user_repository=user_repo,\n",
    "        workspace_name=\"Test Story Workspace\",\n",
    "        user_email=\"test@example.com\",\n",
    "        user_display_name=\"Test User\"\n",
    "    )\n",
    "    print(\"✅ Test story created successfully!\")\n",
    "\n",
    "# Display story summary\n",
    "print()\n",
    "print(story_result.summary())\n",
    "\n",
    "# Extract variables for agent testing (clean interface)\n",
    "STORY: FullStoryBase = story_result.story  # For agent compatibility\n",
    "WORKSPACE_ID = story_result.workspace_id  # For repository operations\n",
    "USER_ID = TEST_USER.id  # For user context\n",
    "STORY_REPO = story_result.story_repository  # Individual repository access\n",
    "WORKSPACE_REPO = story_result.workspace_repository\n",
    "USER_REPO = story_result.user_repository\n",
    "\n",
    "print(f\"\\n🎯 Ready for agent testing!\")\n",
    "print(f\"   📖 STORY: {STORY.metadata.title} ({len(STORY.chapters)} chapters)\")\n",
    "print(f\"   📁 WORKSPACE_ID: {WORKSPACE_ID}\")\n",
    "print(f\"   👤 USER_ID: {USER_ID}\")\n",
    "print(f\"   🔑 Repository types: {type(STORY_REPO).__name__}\")\n",
    "\n",
    "# Verify we're using the same user that has API keys\n",
    "print(f\"\\n🔑 User verification:\")\n",
    "print(f\"   �� Current user ID: {TEST_USER.id}\")\n",
    "print(f\"   👤 Cell 3 user ID: {TEST_USER.id}\")\n",
    "print(f\"   ✅ Same user: {TEST_USER.id == TEST_USER.id}\")\n",
    "\n",
    "# Example: Load any story directory with the same format\n",
    "print(f\"\\n💡 Example: Load any story directory with _meta.xml format:\")\n",
    "print(f\"   story_result = await load_story_with_repositories(\")\n",
    "print(f\"       story_directory=Path('/path/to/your/story'),\")\n",
    "print(f\"       story_repository=story_repo,\")\n",
    "print(f\"       workspace_repository=workspace_repo,\")\n",
    "print(f\"       user_repository=user_repo,\")\n",
    "print(f\"       workspace_name='Custom Workspace',\")\n",
    "print(f\"       user_email='test@example.com'  # Use same user as Cell 3\")\n",
    "print(f\"   )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run individual agents\n",
    "\n",
    "## 📋 WikiGen Agents\n",
    "\n",
    "1. **ArcSplitter Agent** - Analyzes story structure and determines arc boundaries\n",
    "2. **WikiPlanner Agent** - Plans wiki structure and article organization  \n",
    "3. **ArticleWriter Agent** - Generates actual wiki article content\n",
    "4. **GeneralSummarizer Agent** - Creates summaries of various content types\n",
    "5. **ChapterBacklinker Agent** - Creates bidirectional links between chapters and articles\n",
    "6. **WikiGenOrchestrator** - Coordinates the complete workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArcSplitter Agent - Streaming Analysis\n",
    "\n",
    "**🔄 Single LLM Call with Real-time Streaming!**\n",
    "\n",
    "The ArcSplitter agent now supports **streaming analysis** that provides real-time feedback while accumulating the final structured result. This approach uses **only one LLM call** for both user experience and final parsing.\n",
    "\n",
    "- ⚡ **Real-time Feedback** - See analysis progress as it happens\n",
    "- 🚀 **Single LLM Call** - No wasteful duplicate API calls  \n",
    "- 📊 **Live Updates** - Stream response chunks as they're generated\n",
    "- 🎯 **Smart Accumulation** - Parse final accumulated result into structured data\n",
    "- 💰 **Cost Efficient** - One call gives you both streaming UX and structured output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Testing ArcSplitter Agent\n",
      "==================================================\n",
      "🤖 Agent: ArcSplitterAgent\n",
      "📖 Story: Pokemon: Ambertwo (8 chapters)\n",
      "👤 User: 170ba109-1a06-44c8-9388-dd6c356aecd5\n",
      "\n",
      "⚡ Starting analysis...\n",
      "2025-07-02 22:43:42,646 - src.agents.wikigen.arc_splitter - INFO - 🔄 Starting new analysis: bcf62408-28d4-4baa-bc7f-f152461064da\n",
      "2025-07-02 22:43:42,646 - src.agents.wikigen.arc_splitter - INFO - 📐 Model Context Window: 1,048,576 tokens\n",
      "2025-07-02 22:43:42,647 - src.agents.wikigen.arc_splitter - INFO - 📐 Chunk Limit: 1,043,576 tokens (after 5,000 overhead)\n",
      "2025-07-02 22:43:42,647 - src.agents.wikigen.arc_splitter - INFO - 🔍 ArcSplitter Analysis Starting:\n",
      "2025-07-02 22:43:42,648 - src.agents.wikigen.arc_splitter - INFO -    📖 Story: Pokemon: Ambertwo\n",
      "2025-07-02 22:43:42,648 - src.agents.wikigen.arc_splitter - INFO -    📊 Chapters: 8, Words: 19378\n",
      "2025-07-02 22:43:42,650 - src.agents.wikigen.arc_splitter - INFO -    🧮 Total tokens: 27436, Chunk limit: 1043576\n",
      "2025-07-02 22:43:42,651 - src.agents.wikigen.arc_splitter - INFO -    📏 Short story: False\n",
      "2025-07-02 22:43:42,652 - src.agents.wikigen.arc_splitter - INFO - 🔄 Processing window 1: chapters 1-8\n",
      "2025-07-02 22:43:42,652 - src.agents.wikigen.arc_splitter - INFO -    🧮 Chunk tokens: 27436, Final: True\n",
      "2025-07-02 22:43:42,655 - src.agents.wikigen.arc_splitter - INFO -    🤖 Making LLM call for window 1...\n",
      "2025-07-02 22:43:42,656 - src.services.llm.llm_service - INFO - Using database API key for provider=google, model=gemini-2.5-flash-lite-preview-06-17, user=170ba109-1a06-44c8-9388-dd6c356aecd5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-02 22:43:42,717 - src.services.llm.llm_service - INFO - Set strict_open_ai_compliance=False for thinking mode\n",
      "2025-07-02 22:43:42,719 - src.services.llm.llm_service - INFO - Model gemini-2.5-flash-lite-preview-06-17 supports structured output - using response_format parameter\n",
      "2025-07-02 22:43:42,720 - src.services.llm.llm_service - INFO - Using simplified schema for Google Gemini (removed validation constraints)\n",
      "2025-07-02 22:43:42,720 - src.services.llm.llm_service - INFO - Making LLM request: provider=google, model=gemini-2.5-flash-lite-preview-06-17, gateway=http://localhost:8787/v1, streaming=True\n",
      "2025-07-02 22:43:42,720 - src.services.llm.llm_service - INFO - Calculated thinking budget: 3686 tokens for low effort on google/gemini-2.5-flash-lite-preview-06-17\n",
      "2025-07-02 22:43:42,721 - src.services.llm.llm_service - INFO - Using thinking with 3686 budget tokens for Google model gemini-2.5-flash-lite-preview-06-17\n",
      "[THINKING] 398 chars [THINKING] 508 chars [THINKING] 498 chars [THINKING] 382 chars [THINKING] 554 chars [THINKING] 429 chars [THINKING] 404 chars [THINKING] 339 chars [THINKING] 365 chars [THINKING] 360 chars [THINKING] 225 chars [THINKING] 258 chars [THINKING] 291 chars [THINKING] 203 chars [THINKING] 358 chars [THINKING] 188 chars [CONTENT] 78 chars [CONTENT] 258 chars [CONTENT] 278 chars [CONTENT] 474 chars [CONTENT] 249 chars [CONTENT] 265 chars [CONTENT] 216 chars [CONTENT] 264 chars [CONTENT] 268 chars [CONTENT] 209 chars [CONTENT] 263 chars [CONTENT] 286 chars [CONTENT] 278 chars [CONTENT] 275 chars [CONTENT] 282 chars [CONTENT] 238 chars [CONTENT] 305 chars [CONTENT] 285 chars 2025-07-02 22:43:56,505 - src.agents.wikigen.arc_splitter - INFO -    📡 Window 1: 34 streaming responses\n",
      "2025-07-02 22:43:56,506 - src.agents.wikigen.arc_splitter - INFO -    ✅ Window 1: Parsed 1 arcs\n",
      "2025-07-02 22:43:56,507 - src.agents.wikigen.arc_splitter - INFO - ✅ Streaming completed: 1 windows processed\n",
      "\n",
      "✅ Analysis completed!\n",
      "2025-07-02 22:43:56,507 - src.agents.wikigen.arc_splitter - INFO -    ➕ Chunk 1: Added 1 arcs\n",
      "2025-07-02 22:43:56,507 - src.agents.wikigen.arc_splitter - INFO - 🎯 Final result: 1 total arcs merged from 1 chunks\n",
      "\n",
      "📊 Results:\n",
      "   📖 Total arcs: 1\n",
      "\n",
      "🏛️  Arc 1: The Accidental Trainer\n",
      "   📄 Chapters: 1-8\n",
      "   📝 Summary: This arc chronicles the protagonist's sudden death in their original world and their subsequent tran...\n",
      "\n",
      "🎯 ArcSplitter test completed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Test ArcSplitter Agent (Simplified)\n",
    "\n",
    "print(\"🔄 Testing ArcSplitter Agent\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Import the agent and required models\n",
    "from src.agents.wikigen import ArcSplitterAgent\n",
    "from src.schemas.llm.models import ThinkingEffort\n",
    "\n",
    "# Create the agent with simple configuration\n",
    "arc_splitter = ArcSplitterAgent(\n",
    "    llm_service=llm_service,\n",
    "    temperature=0.7,\n",
    "    max_tokens=16000,\n",
    "    thinking=ThinkingEffort.LOW\n",
    ")\n",
    "\n",
    "print(f\"🤖 Agent: {type(arc_splitter).__name__}\")\n",
    "print(f\"📖 Story: {STORY.metadata.title} ({len(STORY.chapters)} chapters)\")\n",
    "print(f\"👤 User: {TEST_USER.id}\")\n",
    "\n",
    "# Run the analysis\n",
    "print(\"\\n⚡ Starting analysis...\")\n",
    "try:\n",
    "    # Stream the analysis\n",
    "    async for chunk in arc_splitter.analyze_story_streaming(\n",
    "        story=STORY,\n",
    "        user_id=TEST_USER.id,\n",
    "    ):\n",
    "        # Show chunk type and length\n",
    "        chunk_type = chunk.chunk_type.value.upper()\n",
    "        content_length = len(chunk.content)\n",
    "        print(f\"[{chunk_type}] {content_length} chars\", end=\" \", flush=True)\n",
    "    \n",
    "    print(\"\\n✅ Analysis completed!\")\n",
    "    \n",
    "    # Get the final result\n",
    "    final_result = arc_splitter.get_final_result()\n",
    "    \n",
    "    print(f\"\\n📊 Results:\")\n",
    "    print(f\"   📖 Total arcs: {len(final_result.arcs)}\")\n",
    "    \n",
    "    # Show each arc\n",
    "    for i, arc in enumerate(final_result.arcs, 1):\n",
    "        print(f\"\\n🏛️  Arc {i}: {arc.title}\")\n",
    "        print(f\"   📄 Chapters: {arc.start_chapter}-{arc.end_chapter}\")\n",
    "        print(f\"   📝 Summary: {arc.summary[:100]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Analysis failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\n🎯 ArcSplitter test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"story_prediction\": \"The narrative is poised to explore the protagonist's journey as a trainer, their quest for identity, and their entanglement with the darker elements of the Pokemon world, particularly Team Rocket and the implications of Mewtwo's existence. Future developments will likely involve the protagonist mastering Ditto's unique abilities, acquiring new Pokemon, challenging Gyms, and uncovering the secrets of Dr. Fuji's research and his connection to Team Rocket. The mystery surrounding Mewtwo's escape and its impact on the world will likely drive significant plot points. Interactions with characters like Erika suggest a focus on uncovering local conspiracies or challenges within Celadon City, which will serve as a stepping stone for broader adventures. The protagonist's meta-knowledge from their previous life will continue to be a source of both advantage and potential danger, especially if it draws unwanted attention from powerful organizations. The ethical implications of cloning and artificial Pokemon creation, as well as the protagonist's own existence as a transplanted consciousness, will likely be explored in depth.\",\n",
      "  \"growth_assessment\": \"This story has substantial potential for growth, easily accommodating a 2-5x expansion. The current 8 chapters have laid the groundwork for multiple future arcs. The protagonist's journey as a trainer, their quest for self-discovery, and their entanglement with the darker elements of the Pokemon world, particularly Team Rocket and the implications of Mewtwo's existence, provide ample material for prolonged narrative arcs. Future content could delve into the protagonist's relationships with new allies and rivals, their confrontations with Team Rocket executives, their attempts to understand or even influence Mewtwo, and the exploration of other regions. Dr. Fuji's scientific endeavors and his potentially complex relationship with Giovanni offer a rich vein for plot development. The world-building, which contrasts game mechanics with a more realistic, gritty portrayal of the Pokemon world, can be further expanded by introducing diverse locations, Pokemon behaviors, and societal structures. The narrative is flexible enough to incorporate new challenges, Pokemon, and plot twists without breaking its core premise.\",\n",
      "  \"arc_strategy\": \"The story is in its nascent stages, with chapters 1-8 serving as an introduction to the protagonist's transmigration, their struggle with identity, the unique mechanics of this Pokemon world, and the initial setup of major plot threads involving Dr. Fuji, Team Rocket, and the escaped Mewtwo. Given the explicit instruction to prioritize fewer, larger arcs to accommodate significant future growth (2-5x current length), a single, comprehensive arc is the most suitable approach. There are no definitive, major story transitions like time skips, setting changes, or protagonist shifts that would warrant splitting the narrative at this point. Instead, the current chapters build a foundational understanding of the protagonist's circumstances and the world they inhabit, creating a cohesive narrative segment that can naturally absorb extensive future developments.\",\n",
      "  \"arcs\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"title\": \"The Accidental Trainer\",\n",
      "      \"start_chapter\": 1,\n",
      "      \"end_chapter\": 8,\n",
      "      \"summary\": \"This arc chronicles the protagonist's sudden death in their original world and their subsequent transmigration into the body of Amber Fuji, the cloned daughter of Dr. Fuji. It covers their initial shock and disorientation, the chaotic escape from a destroyed research facility amidst Mewtwo's rampage, and their journey with Dr. Fuji to Celadon City. The protagonist begins to adapt to their new reality, forging a bond with Ditto, and taking their first steps as a trainer, including their first public battle and an accidental entanglement with Celadon Gym's security. Dr. Fuji's perspective is introduced, revealing his grief, his scientific ambitions, and his involvement with Team Rocket, alongside hints of a larger conspiracy.\",\n",
      "      \"key_events\": \"Protagonist's death in their original world and subsequent transmigration into Amber Fuji's cloned body; awakening to Mewtwo's escape and facility destruction; escape with Dr. Fuji; journey to Cinnabar and then Celadon City; bonding with Ditto and mastering its transformation abilities; first Pokemon battle against Joey; exploration of Celadon City and its trainer culture; encounter with Erika and the greenhouse incident; discovery of Dr. Fuji's past, his work for Team Rocket, and his meeting with Giovanni; protagonist's first steps into the trainer world and accidental involvement in the investigation of a stolen Oddish.\",\n",
      "      \"is_finalized\": true\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(final_result.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiPlanner Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArticleWriterAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneralSummarizerAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiGenOrchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
