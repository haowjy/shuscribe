{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# WikiGen Agent Streaming Workflow\n",
    "\n",
    "This notebook demonstrates **efficient streaming** with WikiGen agents using **single LLM calls** that provide both real-time feedback and structured results.\n",
    "\n",
    "## üéØ Key Principle: One Call, Two Benefits\n",
    "\n",
    "Instead of making wasteful duplicate API calls, we:\n",
    "1. **Stream** for real-time user feedback  \n",
    "2. **Accumulate** content during streaming\n",
    "3. **Parse** accumulated result into structured data\n",
    "\n",
    "**üí∞ Result**: 50% cost savings + better UX!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "‚úÖ Setup complete - ready for efficient streaming tests!\n"
     ]
    }
   ],
   "source": [
    "# Setup and Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "from uuid import uuid4\n",
    "from typing import cast\n",
    "\n",
    "# Set environment for testing\n",
    "os.environ[\"SKIP_DATABASE\"] = \"true\"\n",
    "os.environ[\"PORTKEY_BASE_URL\"] = \"http://localhost:8787/v1\"\n",
    "\n",
    "# Add src to path\n",
    "notebook_dir = Path.cwd()\n",
    "if (notebook_dir / 'src').is_dir():\n",
    "    sys.path.insert(0, str(notebook_dir / 'src'))\n",
    "elif (notebook_dir.parent / 'src').is_dir():\n",
    "    sys.path.insert(0, str(notebook_dir.parent / 'src'))\n",
    "\n",
    "# Import services and agents\n",
    "from src.services.llm.llm_service import LLMService\n",
    "from src.database.repositories import get_user_repository, get_story_repository\n",
    "from src.agents.wikigen.arc_splitter import ArcSplitterAgent\n",
    "from src.schemas.wikigen.arc import ArcAnalysisResult\n",
    "from src.core.story_loading import StoryLoaderFactory\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "print(\"‚úÖ Setup complete - ready for efficient streaming tests!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Available providers: ['openai', 'google', 'anthropic']\n",
      "üìñ Loaded: Pokemon: Ambertwo\n",
      "üìä Chapters: 17, Characters: 273,713\n",
      "üéØ Ready for streaming tests!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Services and Load Test Data\n",
    "\n",
    "# Initialize repositories and LLM service\n",
    "user_repo = get_user_repository()\n",
    "story_repo = get_story_repository()\n",
    "llm_service = LLMService(user_repository=user_repo)\n",
    "\n",
    "# Load API keys from .env\n",
    "env_values = dotenv_values()\n",
    "AVAILABLE_PROVIDERS = {}\n",
    "for provider in LLMService.get_all_llm_providers():\n",
    "    provider_id = provider.provider_id\n",
    "    api_key = env_values.get(f\"{provider_id.upper()}_API_KEY\")\n",
    "    if api_key:\n",
    "        AVAILABLE_PROVIDERS[provider_id] = {\n",
    "            'name': provider.display_name,\n",
    "            'api_key': api_key\n",
    "        }\n",
    "\n",
    "print(f\"üîë Available providers: {list(AVAILABLE_PROVIDERS.keys())}\")\n",
    "\n",
    "# Load test story\n",
    "story_directory_path = Path(\"../tests/resources/pokemon_amber/story\")\n",
    "input_story = StoryLoaderFactory.load_story(story_directory_path)\n",
    "\n",
    "# Store in repository\n",
    "fake_owner_id = uuid4()\n",
    "stored_story = await story_repo.store_input_story(input_story, fake_owner_id)\n",
    "\n",
    "# Prepare story content\n",
    "story_content = \"\\\\n\\\\n\".join([\n",
    "    f\"# {chapter.title}\\\\n{chapter.content}\" \n",
    "    for chapter in input_story.chapters\n",
    "])\n",
    "\n",
    "print(f\"üìñ Loaded: {input_story.metadata.title}\")\n",
    "print(f\"üìä Chapters: {len(input_story.chapters)}, Characters: {len(story_content):,}\")\n",
    "print(f\"üéØ Ready for streaming tests!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üîÑ Efficient Streaming: ArcSplitter Agent\n",
    "\n",
    "**Single LLM call with real-time streaming + structured output**\n",
    "\n",
    "This demonstrates the optimal pattern:\n",
    "- ‚ö° Real-time user feedback during processing\n",
    "- üìä Accumulate content as it streams  \n",
    "- üéØ Parse final result into structured data\n",
    "- üí∞ **Only one API call** - no waste!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Testing with: openai / gpt-4.1-nano\n",
      "üìñ Story: Pokemon: Ambertwo (17 chapters)\n",
      "\\n‚ö° Starting efficient streaming analysis...\n",
      "üì° Live stream output:\n",
      "--------------------------------------------------\n",
      "2025-06-29 01:41:16,933 - src.services.llm.llm_service - INFO - Using direct API key for provider=openai, model=gpt-4.1-nano\n",
      "2025-06-29 01:41:16,962 - src.services.llm.llm_service - INFO - Model gpt-4.1-nano supports structured output - using response_format parameter\n",
      "2025-06-29 01:41:16,962 - src.services.llm.llm_service - INFO - Using standard schema for provider: openai\n",
      "2025-06-29 01:41:16,962 - src.services.llm.llm_service - INFO - Making LLM request: provider=openai, model=gpt-4.1-nano, gateway=http://localhost:8787/v1, streaming=True\n",
      "{\"arcs\":[{\"id\":1,\"title\":\"Introduction and Sudden Transition to a New World\",\"start_chapter\":1,\"end_chapter\":2,\"summary\":\"The story begins with the protagonist immersed in a Pok√©mon battle on their phone, which is abruptly interrupted by a mysterious accident involving Mewtwo and Dr. Fuji. The protagonist is transported into a new, real-world environment, experiencing the shock of their body being that of Dr. Fuji's daughter, and witnessing the chaos of a Pok√©mon battle in a laboratory. This arc establishes the protagonist's initial circumstances, the transition from their old life to the new world, and the immediate danger and confusion they face.\",\"key_events\":\"Protagonist's last battle on phone; notification about Shadow Mewtwo raid; sudden transportation into Dr. Fuji's lab; encounter with Mewtwo and Dr. Fuji; chaos of the lab breach; realization of being in a new, real-world environment; initial shock and confusion.\"},{\"id\":2,\"title\":\"Adjustment to the New Reality and Early Exploration\",\"start_chapter\":3,\"end_chapter\":4,\"summary\":\"The protagonist begins to acclimate to their new body and environment, including dressing and interacting with Ditto. They explore the laboratory ruins, witness Pok√©mon battles in the city, and start to understand the world they are in‚Äîan Earth where Pok√©mon are integrated into daily life. The protagonist also takes their first steps toward becoming a Pok√©mon trainer, observing battles and practicing with Ditto, setting the foundation for their future journey.\",\"key_events\":\"Fitting into Dr. Fuji's daughter‚Äôs body; transforming Ditto; observing Pok√©mon battles on TV; exploring Celadon City; planning to visit the gym; first real-world Pok√©mon encounters.\"},{\"id\":3,\"title\":\"First Pok√©mon Battle and Beginning of Training\",\"start_chapter\":5,\"end_chapter\":6,\"summary\":\"The protagonist visits Celadon Gym and witnesses Pok√©mon battles in the city park, gaining insight into real Pok√©mon combat. They then engage in their first battle with a young trainer, testing Ditto‚Äôs abilities and starting their journey as a trainer. This arc marks the transition from observer to active participant in the Pok√©mon world, emphasizing the protagonist‚Äôs determination and adaptation.\",\"key_events\":\"Visiting Celadon Gym; observing battles; engaging in their first battle with Joey‚Äôs Rattata; testing Ditto‚Äôs capabilities; solidifying the desire to train and grow stronger.\"},{\"id\":4,\"title\":\"Training, Strategy, and Building Confidence\",\"start_chapter\":7,\"end_chapter\":9,\"summary\":\"The protagonist dedicates time to training Ditto, experimenting with transformations, and learning how to utilize their Pok√©mon effectively. They practice transforming into various Pok√©mon, study battle tactics, and build confidence in their abilities. This arc focuses on character growth, developing skills, and preparing for future challenges.\",\"key_events\":\"Practicing transformations; training Ditto with different Pok√©mon; gaining confidence; understanding the importance of strategy; preparing for upcoming battles.\"},{\"id\":5,\"title\":\"Encounter with a Challenger and the First Tournament\",\"start_chapter\":10,\"end_chapter\":12,\"summary\":\"The protagonist faces a new challenger, Joey, in an impromptu battle, testing their skills under pressure. They participate in a local Pok√©mon tournament, confronting stronger opponents and applying their training. This arc represents a significant step in their journey, showcasing growth, resilience, and the challenges of real competition.\",\"key_events\":\"Joey‚Äôs challenge; tournament participation; applying training in real battles; overcoming initial setbacks; gaining experience.\"},{\"id\":6,\"title\":\"Deeper Mysteries and the Threat of Team Rocket\",\"start_chapter\":13,\"end_chapter\":15,\"summary\":\"The story delves into the larger conspiracy involving Team Rocket and the secret experiments behind Mewtwo‚Äôs creation. The protagonist uncovers hints of their own importance in the ongoing conflict and the potential dangers of their unique situation. This arc introduces a new antagonist force and raises the stakes for the protagonist‚Äôs future.\",\"key_events\":\"Discovery of Team Rocket‚Äôs involvement; uncovering the secret behind Mewtwo; realizing their own significance; facing new threats.\"},{\"id\":7,\"title\":\"Climax, Resolution, and New Beginnings\",\"start_chapter\":16,\"end_chapter\":17,\"summary\":\"The protagonist confronts the climax of the story, dealing with the threats posed by Team Rocket and the chaos caused by Mewtwo. They make critical decisions that determine their future and the fate of the Pok√©mon world. The story concludes with a sense of hope and new purpose, setting the stage for further adventures.\",\"key_events\":\"Final confrontation with Team Rocket; resolving the chaos caused by Mewtwo; character growth and acceptance; looking forward to future adventures.\"}],\"story_prediction\":\"The story is likely to continue exploring the protagonist‚Äôs growth as a trainer, deeper involvement in the Pok√©mon world‚Äôs conflicts, and possibly uncovering more about their origin and purpose. Future plot directions may include more encounters with legendary Pok√©mon, alliances with other trainers, and the resolution of the overarching conspiracy involving Team Rocket.\",\"growth_assessment\":\"The story is expanding from initial shock and discovery to active participation and strategic development. The protagonist‚Äôs understanding of the Pok√©mon world deepens, and their skills improve, setting the stage for more complex challenges and character development.\",\"consolidation_reasoning\":\"The story‚Äôs length and complexity suggest that these arcs are natural divisions that allow for coherent storytelling, character growth, and plot advancement. Each arc builds upon the previous, ensuring a logical progression while leaving room for future expansion.\",\"arc_strategy\":\"The division strategy was to start with the protagonist‚Äôs sudden arrival and initial adaptation, then move through their growth as a trainer, encounters with opponents, and the uncovering of larger threats. Each arc ends at a natural story beat‚Äîsuch as a battle, discovery, or decision‚Äîmaking them suitable for detailed wiki articles.\"}\\n--------------------------------------------------\n",
      "‚úÖ Streaming completed with single LLM call!\n",
      "üìä Chunks received: 1194\n",
      "üìù Content length: 6181 chars\n",
      "\\nüîç Parsing streamed content...\n",
      "‚úÖ Successfully parsed streaming result!\n",
      "‚ö†Ô∏è  Parse error: 'ArcAnalysisResult' object has no attribute 'story_stats'\n",
      "üìÑ Raw content: {\"arcs\":[{\"id\":1,\"title\":\"Introduction and Sudden Transition to a New World\",\"start_chapter\":1,\"end_chapter\":2,\"summary\":\"The story begins with the protagonist immersed in a Pok√©mon battle on their ph...\n",
      "üí° Note: Some models may not return valid JSON in streaming mode\n"
     ]
    }
   ],
   "source": [
    "# Efficient Streaming Test - Single LLM Call\n",
    "\n",
    "if not AVAILABLE_PROVIDERS:\n",
    "    print(\"‚ùå No API keys available. Please add API keys to your .env file.\")\n",
    "else:\n",
    "    # Use first available provider\n",
    "    provider = list(AVAILABLE_PROVIDERS.keys())[0]\n",
    "    api_key = AVAILABLE_PROVIDERS[provider]['api_key']\n",
    "    model = LLMService.get_default_test_model_name_for_provider(provider)\n",
    "    \n",
    "    print(f\"üîß Testing with: {provider} / {model}\")\n",
    "    print(f\"üìñ Story: {input_story.metadata.title} ({len(input_story.chapters)} chapters)\")\n",
    "    \n",
    "    # Initialize agent\n",
    "    arc_splitter = ArcSplitterAgent(\n",
    "        llm_service=llm_service,\n",
    "        default_provider=provider,\n",
    "        default_model=model\n",
    "    )\n",
    "    \n",
    "    print(f\"\\\\n‚ö° Starting efficient streaming analysis...\")\n",
    "    print(\"üì° Live stream output:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # üéØ EFFICIENT PATTERN: Single call with streaming + accumulation\n",
    "    accumulated_content = \"\"\n",
    "    chunk_count = 0\n",
    "    \n",
    "    async for chunk in arc_splitter.analyze_story_streaming(\n",
    "        story_title=input_story.metadata.title,\n",
    "        story_content=story_content[:50000],  # Truncate for demo\n",
    "        total_chapters=len(input_story.chapters),\n",
    "        user_id=fake_owner_id,\n",
    "        api_key=api_key,\n",
    "        genre=\"Isekai Fantasy\"\n",
    "    ):\n",
    "        chunk_count += 1\n",
    "        content = chunk.content\n",
    "        accumulated_content += content  # üìä Accumulate for parsing\n",
    "        \n",
    "        # ‚ö° Real-time feedback to user\n",
    "        if content:\n",
    "            print(content, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\\\n\" + \"-\" * 50)\n",
    "    print(f\"‚úÖ Streaming completed with single LLM call!\")\n",
    "    print(f\"üìä Chunks received: {chunk_count}\")\n",
    "    print(f\"üìù Content length: {len(accumulated_content)} chars\")\n",
    "    \n",
    "    # üéØ Parse accumulated result into structured format\n",
    "    print(f\"\\\\nüîç Parsing streamed content...\")\n",
    "    try:\n",
    "        # Parse the accumulated JSON response\n",
    "        final_result = ArcAnalysisResult.model_validate_json(accumulated_content)\n",
    "        \n",
    "        print(f\"‚úÖ Successfully parsed streaming result!\")\n",
    "        print(f\"üìã Recommended arcs: {final_result.story_stats.recommended_arcs}\")\n",
    "        print(f\"üìñ Generated arcs: {len(final_result.arcs)}\")\n",
    "        \n",
    "        # Show first arc as example\n",
    "        if final_result.arcs:\n",
    "            first_arc = final_result.arcs[0]\n",
    "            print(f\"\\\\nüèõÔ∏è  Arc 1: {first_arc.title}\")\n",
    "            print(f\"   üìñ Chapters: {first_arc.start_chapter}-{first_arc.end_chapter}\")\n",
    "            print(f\"   üìù Summary: {first_arc.summary[:100]}...\")\n",
    "            \n",
    "        print(f\"\\\\nüéØ SUCCESS: Real-time streaming + structured output with single API call!\")\n",
    "        \n",
    "    except Exception as parse_error:\n",
    "        print(f\"‚ö†Ô∏è  Parse error: {parse_error}\")\n",
    "        print(f\"üìÑ Raw content: {accumulated_content[:200]}...\")\n",
    "        print(\"üí° Note: Some models may not return valid JSON in streaming mode\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üìä Pattern Comparison\n",
    "\n",
    "### ‚úÖ EFFICIENT: Single Call with Accumulation\n",
    "```python\n",
    "accumulated_content = \"\"\n",
    "async for chunk in agent.analyze_story_streaming(...):\n",
    "    print(chunk.content, end=\"\", flush=True)    # Real-time feedback\n",
    "    accumulated_content += chunk.content        # Accumulate content\n",
    "\n",
    "# Parse accumulated result\n",
    "result = ArcAnalysisResult.model_validate_json(accumulated_content)\n",
    "```\n",
    "\n",
    "### ‚ùå WASTEFUL: Double API Calls  \n",
    "```python\n",
    "# Call 1: Streaming (costs money)\n",
    "async for chunk in agent.analyze_story_streaming(...):\n",
    "    print(chunk.content, end=\"\")\n",
    "    \n",
    "# Call 2: Non-streaming (costs money again!)\n",
    "result = await agent.analyze_story(...)  # DUPLICATE WORK!\n",
    "```\n",
    "\n",
    "### üéØ Benefits of Efficient Pattern\n",
    "- üí∞ **50% cost reduction** - One call instead of two\n",
    "- ‚ö° **Better performance** - No duplicate processing  \n",
    "- üîÑ **Same UX** - Real-time streaming feedback\n",
    "- üìä **Same output** - Structured data for downstream use\n",
    "- üå± **Environmentally friendly** - Less compute waste\n",
    "\n",
    "**Conclusion**: Always use streaming with accumulation for the best balance of cost, performance, and user experience!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiGen Agent Workflow Testing\n",
    "\n",
    "This notebook provides an environment to test the WikiGen agent-based story processing workflow using the new **BaseAgent architecture**. Each agent can be tested individually with different LLM models to demonstrate the flexibility and modularity of the system.\n",
    "\n",
    "## üèóÔ∏è BaseAgent Architecture\n",
    "\n",
    "All WikiGen agents now inherit from `BaseAgent`, providing:\n",
    "- **Default Models**: Each agent has configurable default provider/model\n",
    "- **Override Flexibility**: Can override provider/model per call when needed  \n",
    "- **Centralized LLM Logic**: Common error handling and validation\n",
    "- **Clean API**: Simplified method signatures with optional parameters\n",
    "\n",
    "## üìã WikiGen Agents\n",
    "\n",
    "1. **ArcSplitter Agent** - Analyzes story structure and determines arc boundaries\n",
    "2. **WikiPlanner Agent** - Plans wiki structure and article organization  \n",
    "3. **ArticleWriter Agent** - Generates actual wiki article content\n",
    "4. **GeneralSummarizer Agent** - Creates summaries of various content types\n",
    "5. **ChapterBacklinker Agent** - Creates bidirectional links between chapters and articles\n",
    "6. **WikiGenOrchestrator** - Coordinates the complete workflow\n",
    "\n",
    "Each agent demonstrates the BaseAgent pattern with different default models to show architectural flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup\n",
    "\n",
    "Make sure the Portkey Gateway is running to use the LLM Service:\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  --name portkey-gateway \\\n",
    "  -p 8787:8787 \\\n",
    "  portkeyai/gateway:latest\n",
    "```\n",
    "\n",
    "The following cells will:\n",
    "- use the Portkey Gateway to test the LLM Service\n",
    "- initialize the LLM Service\n",
    "- import the WikiGen workflow agents\n",
    "- load a test story from the `tests/resources/pokemon_amber/story` directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "üöÄ WikiGen Agent Workflow Testing Environment\n",
      "============================================================\n",
      "Current working directory: /home/jimnix/gitrepos/shuscribe/backend/notebooks\n",
      "Database mode: IN-MEMORY\n",
      "Portkey Gateway: http://localhost:8787/v1\n",
      "Autoreload enabled. Changes to .py files in src/ will be reloaded.\n",
      "\n",
      "üí° This notebook tests WikiGen agents with real LLM calls.\n",
      "   Each agent can use different models to demonstrate flexibility.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Configuration\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import logging\n",
    "from uuid import uuid4\n",
    "from typing import Dict, Any, List, cast\n",
    "\n",
    "# Set environment to skip database for testing\n",
    "os.environ[\"SKIP_DATABASE\"] = \"true\"\n",
    "os.environ[\"PORTKEY_BASE_URL\"] = \"http://localhost:8787/v1\"  # Default Portkey Gateway\n",
    "\n",
    "# Add the backend/src directory to sys.path\n",
    "notebook_dir = Path.cwd()\n",
    "if (notebook_dir / 'src').is_dir() and (notebook_dir / 'pyproject.toml').is_file():\n",
    "    # This means we're likely in the backend/ directory itself\n",
    "    sys.path.insert(0, str(notebook_dir / 'src'))\n",
    "elif (notebook_dir.parent / 'src').is_dir() and (notebook_dir.parent / 'pyproject.toml').is_file():\n",
    "    # This means we're likely in the backend/notebooks/ directory\n",
    "    sys.path.insert(0, str(notebook_dir.parent / 'src'))\n",
    "else:\n",
    "    print(\"Warning: Could not automatically add 'src/' to Python path.\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "# Reduce noise from third-party loggers\n",
    "logging.getLogger('httpx').setLevel(logging.WARNING)\n",
    "logging.getLogger('uvicorn.access').setLevel(logging.WARNING)\n",
    "\n",
    "print(\"üöÄ WikiGen Agent Workflow Testing Environment\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Database mode: {'IN-MEMORY' if os.environ.get('SKIP_DATABASE') == 'true' else 'SUPABASE'}\")\n",
    "print(f\"Portkey Gateway: {os.environ.get('PORTKEY_BASE_URL', 'Not configured')}\")\n",
    "print(\"Autoreload enabled. Changes to .py files in src/ will be reloaded.\")\n",
    "print(\"\\nüí° This notebook tests WikiGen agents with real LLM calls.\")\n",
    "print(\"   Each agent can use different models to demonstrate flexibility.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modules imported successfully.\n",
      "\n",
      "--- Current Settings ---\n",
      "DEBUG: True\n",
      "ENVIRONMENT: development\n",
      "SKIP_DATABASE: True\n",
      "PORTKEY_BASE_URL: http://localhost:8787/v1\n",
      "DATABASE_MODE: In-Memory (Supabase skipped)\n",
      "------------------------\n",
      "\n",
      "üîß Import Summary:\n",
      "‚úÖ LLMService - Ready for testing\n",
      "‚úÖ WikiGen Agents - All 5 agents + orchestrator imported\n",
      "‚úÖ Story Loading - Test story will be loaded\n",
      "‚úÖ Repository Factory - In-memory repositories for testing\n",
      "‚úÖ Pydantic Models - Type-safe schemas\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Modules\n",
    "from src.config import settings\n",
    "from src.services.llm.llm_service import LLMService\n",
    "from src.database.repositories import get_user_repository, get_story_repository\n",
    "from src.schemas.llm.models import LLMMessage, LLMResponse\n",
    "from src.core.story_loading import StoryLoaderFactory\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# WikiGen agent imports\n",
    "from src.agents.wikigen import (\n",
    "    WikiGenOrchestrator,\n",
    "    ArcSplitterAgent,\n",
    "    WikiPlannerAgent,\n",
    "    ArticleWriterAgent,\n",
    "    GeneralSummarizerAgent,\n",
    "    ChapterBacklinkerAgent\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Modules imported successfully.\")\n",
    "\n",
    "# Display current settings\n",
    "print(\"\\n--- Current Settings ---\")\n",
    "print(f\"DEBUG: {settings.DEBUG}\")\n",
    "print(f\"ENVIRONMENT: {settings.ENVIRONMENT}\")\n",
    "print(f\"SKIP_DATABASE: {settings.SKIP_DATABASE}\")\n",
    "print(f\"PORTKEY_BASE_URL: {settings.PORTKEY_BASE_URL}\")\n",
    "print(\"DATABASE_MODE: In-Memory (Supabase skipped)\")\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"\\nüîß Import Summary:\")\n",
    "print(\"‚úÖ LLMService - Ready for testing\")\n",
    "print(\"‚úÖ WikiGen Agents - All 5 agents + orchestrator imported\") \n",
    "print(\"‚úÖ Story Loading - Test story will be loaded\")\n",
    "print(\"‚úÖ Repository Factory - In-memory repositories for testing\")\n",
    "print(\"‚úÖ Pydantic Models - Type-safe schemas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Services and Loading Test Story...\n",
      "============================================================\n",
      "‚úÖ Services initialized successfully!\n",
      "üìÅ Repository types: InMemoryUserRepository, InMemoryStoryRepository\n",
      "\n",
      "üîë Loading API Keys from .env...\n",
      "‚úÖ OpenAI: API key found\n",
      "‚úÖ Google: API key found\n",
      "‚úÖ Anthropic: API key found\n",
      "\n",
      "üìä Available Providers: 3\n",
      "\n",
      "üìñ Loading Test Story...\n",
      "‚úÖ Loaded: Pokemon: Ambertwo\n",
      "   Author: ChronicImmortality\n",
      "   Chapters: 17\n",
      "   Genres: Drama, Action, Adventure, Fantasy\n",
      "   Stored with ID: 3a19f5df-e91d-4597-a021-636dbd623f3b\n",
      "\n",
      "üìä Test Data Summary:\n",
      "   Total characters: 273,664\n",
      "   First chapter: [Chapter 1] Truck-kun Strikes Again\n",
      "   Last chapter: [Chapter 17] The Eye of the Storm\n",
      "\n",
      "üéØ Ready for WikiGen agent testing with 3 LLM providers!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize Services and Load Test Story\n",
    "\n",
    "print(\"üöÄ Initializing Services and Loading Test Story...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize repositories and LLM service\n",
    "user_repo = get_user_repository()\n",
    "story_repo = get_story_repository()\n",
    "llm_service = LLMService(user_repository=user_repo)\n",
    "\n",
    "print(\"‚úÖ Services initialized successfully!\")\n",
    "print(f\"üìÅ Repository types: {type(user_repo).__name__}, {type(story_repo).__name__}\")\n",
    "\n",
    "# Load API keys from .env\n",
    "env_values = dotenv_values()\n",
    "print(\"\\nüîë Loading API Keys from .env...\")\n",
    "\n",
    "# Check which providers have API keys available\n",
    "AVAILABLE_PROVIDERS: dict[str, dict[str, str]] = {}\n",
    "for provider in LLMService.get_all_llm_providers():\n",
    "    provider_id = provider.provider_id\n",
    "    api_key = env_values.get(f\"{provider_id.upper()}_API_KEY\")\n",
    "    if api_key:\n",
    "        AVAILABLE_PROVIDERS[provider_id] = {\n",
    "            'name': provider.display_name,\n",
    "            'api_key': api_key\n",
    "        }\n",
    "        print(f\"‚úÖ {provider.display_name}: API key found\")\n",
    "    else:\n",
    "        print(f\"‚è≠Ô∏è  {provider.display_name}: No API key found\")\n",
    "\n",
    "print(f\"\\nüìä Available Providers: {len(AVAILABLE_PROVIDERS)}\")\n",
    "\n",
    "# Load test story\n",
    "print(\"\\nüìñ Loading Test Story...\")\n",
    "story_directory_path = Path(\"../tests/resources/pokemon_amber/story\")\n",
    "\n",
    "try:\n",
    "    input_story = StoryLoaderFactory.load_story(story_directory_path)\n",
    "    print(f\"‚úÖ Loaded: {input_story.metadata.title}\")\n",
    "    print(f\"   Author: {input_story.metadata.author}\")\n",
    "    print(f\"   Chapters: {input_story.total_chapters}\")\n",
    "    print(f\"   Genres: {', '.join(input_story.metadata.genres)}\")\n",
    "    \n",
    "    # Store in repository for testing\n",
    "    fake_owner_id = uuid4()\n",
    "    stored_story = await story_repo.store_input_story(input_story, fake_owner_id)\n",
    "    print(f\"   Stored with ID: {stored_story.id}\")\n",
    "    \n",
    "    # Prepare story content for agent testing\n",
    "    story_content = \"\\n\\n\".join([\n",
    "        f\"# {chapter.title}\\n{chapter.content}\" \n",
    "        for chapter in input_story.chapters\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nüìä Test Data Summary:\")\n",
    "    print(f\"   Total characters: {len(story_content):,}\")\n",
    "    print(f\"   First chapter: {input_story.chapters[0].title}\")\n",
    "    print(f\"   Last chapter: {input_story.chapters[-1].title}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading story: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\nüéØ Ready for WikiGen agent testing with {len(AVAILABLE_PROVIDERS)} LLM providers!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run individual agents\n",
    "\n",
    "## üìã WikiGen Agents\n",
    "\n",
    "1. **ArcSplitter Agent** - Analyzes story structure and determines arc boundaries\n",
    "2. **WikiPlanner Agent** - Plans wiki structure and article organization  \n",
    "3. **ArticleWriter Agent** - Generates actual wiki article content\n",
    "4. **GeneralSummarizer Agent** - Creates summaries of various content types\n",
    "5. **ChapterBacklinker Agent** - Creates bidirectional links between chapters and articles\n",
    "6. **WikiGenOrchestrator** - Coordinates the complete workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArcSplitter Agent - Streaming Analysis\n",
    "\n",
    "**üîÑ Single LLM Call with Real-time Streaming!**\n",
    "\n",
    "The ArcSplitter agent now supports **streaming analysis** that provides real-time feedback while accumulating the final structured result. This approach uses **only one LLM call** for both user experience and final parsing.\n",
    "\n",
    "- ‚ö° **Real-time Feedback** - See analysis progress as it happens\n",
    "- üöÄ **Single LLM Call** - No wasteful duplicate API calls  \n",
    "- üìä **Live Updates** - Stream response chunks as they're generated\n",
    "- üéØ **Smart Accumulation** - Parse final accumulated result into structured data\n",
    "- üí∞ **Cost Efficient** - One call gives you both streaming UX and structured output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Testing ArcSplitter Agent - STREAMING Analysis\n",
      "============================================================\n",
      "This demonstrates real-time streaming during story analysis.\n",
      "üí° You'll see the analysis progress in real-time as chunks arrive!\n",
      "üîß Streaming with: google / gemini-2.0-flash-001\n",
      "üìä Story: Pokemon: Ambertwo (17 chapters)\n",
      "\\n‚ö° Starting streaming analysis...\n",
      "üì° Live stream output:\n",
      "----------------------------------------\n",
      "2025-06-29 01:42:42,412 - src.services.llm.llm_service - INFO - Using direct API key for provider=google, model=gemini-2.0-flash-001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-29 01:42:42,441 - src.services.llm.llm_service - INFO - Model gemini-2.0-flash-001 supports structured output - using response_format parameter\n",
      "2025-06-29 01:42:42,442 - src.services.llm.llm_service - INFO - Using simplified schema for Google Gemini (removed validation constraints)\n",
      "2025-06-29 01:42:42,442 - src.services.llm.llm_service - INFO - Making LLM request: provider=google, model=gemini-2.0-flash-001, gateway=http://localhost:8787/v1, streaming=True\n",
      "2025-06-29 01:42:45,992 - portkey_ai._vendor.openai._base_client - INFO - Retrying request to /chat/completions in 0.461047 seconds\n",
      "‚ùå Streaming test failed: Error code: 503 - {'error': {'message': 'Invalid response received from google: [{\"error\":{\"code\":503,\"message\":\"The model is overloaded. Please try again later.\",\"status\":\"UNAVAILABLE\"}}]', 'type': None, 'param': None, 'code': None}, 'provider': 'google'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_159698/2464946418.py\", line 34, in <module>\n",
      "    async for chunk in arc_splitter_streaming.analyze_story_streaming(\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/src/agents/wikigen/arc_splitter.py\", line 198, in analyze_story_streaming\n",
      "    async for chunk in response_stream:\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/src/services/llm/llm_service.py\", line 302, in _stream_response_to_llm_response\n",
      "    else:\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages/portkey_ai/api_resources/apis/chat_complete.py\", line 323, in stream_create\n",
      "    async with self.openai_client.with_streaming_response.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages/portkey_ai/_vendor/openai/_response.py\", line 650, in __aenter__\n",
      "    self.__response = await self._api_request\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages/portkey_ai/_vendor/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages/portkey_ai/_vendor/openai/_base_client.py\", line 1765, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages/portkey_ai/_vendor/openai/_base_client.py\", line 1572, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.InternalServerError: Error code: 503 - {'error': {'message': 'Invalid response received from google: [{\"error\":{\"code\":503,\"message\":\"The model is overloaded. Please try again later.\",\"status\":\"UNAVAILABLE\"}}]', 'type': None, 'param': None, 'code': None}, 'provider': 'google'}\n"
     ]
    }
   ],
   "source": [
    "# Cell: 4 Test ArcSplitter Agent - Streaming Version\n",
    "\n",
    "print(\"\\nüîÑ Testing ArcSplitter Agent - STREAMING Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This demonstrates real-time streaming during story analysis.\")\n",
    "print(\"üí° You'll see the analysis progress in real-time as chunks arrive!\")\n",
    "\n",
    "if not AVAILABLE_PROVIDERS:\n",
    "    print(\"‚ùå No API keys available. Please add API keys to your .env file.\")\n",
    "else:\n",
    "    provider = \"openai\"  # Use Google for streaming demo    \n",
    "    api_key = AVAILABLE_PROVIDERS[provider]['api_key']\n",
    "    model = LLMService.get_default_test_model_name_for_provider(provider)\n",
    "    \n",
    "    print(f\"üîß Streaming with: {provider} / {model}\")\n",
    "    print(f\"üìä Story: {input_story.metadata.title} ({len(input_story.chapters)} chapters)\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize the agent\n",
    "        arc_splitter_streaming = ArcSplitterAgent(\n",
    "            llm_service=llm_service,\n",
    "            default_provider=provider,\n",
    "            default_model=model\n",
    "        )\n",
    "        \n",
    "        print(f\"\\\\n‚ö° Starting streaming analysis...\")\n",
    "        print(\"üì° Live stream output:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Stream the analysis in real-time and accumulate the response\n",
    "        chunk_count = 0\n",
    "        accumulated_content = \"\"\n",
    "        \n",
    "        async for chunk in arc_splitter_streaming.analyze_story_streaming(\n",
    "            story_title=input_story.metadata.title,\n",
    "            story_content=story_content,  # Truncate for faster demo\n",
    "            total_chapters=len(input_story.chapters),\n",
    "            user_id=fake_owner_id,\n",
    "            api_key=api_key,\n",
    "            genre=\"Isekai Fantasy\"\n",
    "        ):\n",
    "            chunk_count += 1\n",
    "            content = chunk.content\n",
    "            accumulated_content += content\n",
    "            \n",
    "            # Print streaming content in real-time\n",
    "            if content:\n",
    "                print(content, end=\"\", flush=True)\n",
    "        \n",
    "        print(\"\\\\n\" + \"-\" * 40)\n",
    "        print(f\"‚úÖ Streaming completed with single LLM call!\")\n",
    "        print(f\"üìä Total chunks received: {chunk_count}\")\n",
    "        print(f\"üìù Total content length: {len(accumulated_content)} characters\")\n",
    "        \n",
    "        # Parse the accumulated streaming result into structured format\n",
    "        print(f\"\\\\nüéØ Parsing streamed content into structured result...\")\n",
    "        try:\n",
    "            from src.schemas.wikigen.arc import ArcAnalysisResult\n",
    "            \n",
    "            # Parse the accumulated JSON response from streaming\n",
    "            final_result = ArcAnalysisResult.model_validate_json(accumulated_content)\n",
    "            \n",
    "            print(f\"‚úÖ Successfully parsed streaming result!\")\n",
    "            print(f\"üìñ Number of arcs generated: {len(final_result.arcs)}\")\n",
    "            \n",
    "            # Show first arc as example\n",
    "            if final_result.arcs:\n",
    "                first_arc = final_result.arcs[0]\n",
    "                print(f\"\\\\nüèõÔ∏è  First Arc: {first_arc.title}\")\n",
    "                print(f\"   üìñ Chapters: {first_arc.start_chapter}-{first_arc.end_chapter}\")\n",
    "                print(f\"   üìù Summary: {first_arc.summary[:100]}...\")\n",
    "                \n",
    "        except Exception as parse_error:\n",
    "            print(f\"‚ö†Ô∏è  Could not parse streaming result: {parse_error}\")\n",
    "            print(f\"üìÑ Raw content preview: {accumulated_content[:200]}...\")\n",
    "            print(\"üí° This is expected if the model doesn't return valid JSON in streaming mode\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Streaming test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\nüß™ Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"‚ö†Ô∏è  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\nüß™ Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"‚ö†Ô∏è  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\nüß™ Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"‚ö†Ô∏è  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\nüß™ Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"‚ö†Ô∏è  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\nüß™ Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"‚ö†Ô∏è  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\nüß™ Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"‚ö†Ô∏è  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\nüß™ Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"‚ö†Ô∏è  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"story_stats\": {\n",
      "    \"recommended_arcs\": 4,\n",
      "    \"arc_strategy\": \"The story was divided into four arcs based on significant shifts in location, plot, and character relationships. The first arc covers Ambertwo's rebirth and escape from the lab. The second arc focuses on her exploration of Celadon City and the reveal of Dr. Fuji's Team Rocket connections. The third arc involves the side quest with the Celadon Gym. The final arc covers the climax in Pallet Town and Ambertwo's new life with Delia and Stephen.\"\n",
      "  },\n",
      "  \"arcs\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"title\": \"Rebirth and Escape\",\n",
      "      \"start_chapter\": 1,\n",
      "      \"end_chapter\": 2,\n",
      "      \"summary\": \"Alexa dies after being hit by a truck while playing Pokemon Go and is reborn as Ambertwo, a clone of Dr. Fuji's deceased daughter Amber. She escapes the lab with Dr. Fuji and begins to adjust to the Pokemon world.\",\n",
      "      \"key_events\": \"Character dies and is reborn as Ambertwo, Dr. Fuji reveals his intentions to recreate his dead daughter, Ambertwo grapples with her new identity and the knowledge of the Pokemon world, the pair escape the underground lab and take the Pidgeot Express to Celadon City.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"title\": \"Celadon City and Team Rocket\",\n",
      "      \"start_chapter\": 3,\n",
      "      \"end_chapter\": 6,\n",
      "      \"summary\": \"Ambertwo begins to explore Celadon City and train with Ditto. She has her first Pokemon battle and is caught trespassing in the Celadon Gym greenhouse. Meanwhile, Dr. Fuji's connection to Team Rocket is revealed.\",\n",
      "      \"key_events\": \"Ambertwo explores Celadon City, battles Joey, and is caught trespassing in the Celadon Gym greenhouse. Dr. Fuji's activities with Team Rocket are revealed as he attempts to find his wife.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"title\": \"The Great Oddish Heist\",\n",
      "      \"start_chapter\": 7,\n",
      "      \"end_chapter\": 10,\n",
      "      \"summary\": \"Ambertwo and Mary investigate a theft at the Celadon Gym, leading them to a girl trying to save her sick brother. They enlist Erika's help and resolve the situation. Dr. Fuji reclaims Ditto and punishes Ambertwo, setting the stage for a new direction in the story.\",\n",
      "      \"key_events\": \"Ambertwo and Mary investigate a theft at the Celadon Gym, befriend Erika, and help a sick child. Dr. Fuji reclaims Ditto and punishes Ambertwo.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"title\": \"Pallet Town and the Final Confrontation\",\n",
      "      \"start_chapter\": 11,\n",
      "      \"end_chapter\": 17,\n",
      "      \"summary\": \"Dr. Fuji takes Ambertwo to Pallet Town, where he confronts Delia and Stephen. He attacks Stephen and Delia's home, leading to a battle with Professor Oak and his subsequent arrest. Ambertwo is left in the care of Delia and Stephen, beginning a new chapter in her life.\",\n",
      "      \"key_events\": \"Dr. Fuji takes Ambertwo to Pallet Town and attempts to force her into his idealized version of their family, leading to a confrontation with Delia and Stephen. Dr. Fuji attacks Stephen and Delia's home, resulting in a battle with Professor Oak and his subsequent arrest. Ambertwo is left in the care of Delia and Stephen.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(final_result.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiPlanner Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArticleWriterAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneralSummarizerAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiGenOrchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
