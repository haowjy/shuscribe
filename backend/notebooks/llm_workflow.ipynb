{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiGen Agent Workflow Testing\n",
    "\n",
    "This notebook provides an environment to test the WikiGen agent-based story processing workflow using the new **BaseAgent architecture**. Each agent can be tested individually with different LLM models to demonstrate the flexibility and modularity of the system.\n",
    "\n",
    "## ğŸ—ï¸ BaseAgent Architecture\n",
    "\n",
    "All WikiGen agents now inherit from `BaseAgent`, providing:\n",
    "- **Default Models**: Each agent has configurable default provider/model\n",
    "- **Override Flexibility**: Can override provider/model per call when needed  \n",
    "- **Centralized LLM Logic**: Common error handling and validation\n",
    "- **Clean API**: Simplified method signatures with optional parameters\n",
    "\n",
    "## ğŸ“‹ WikiGen Agents\n",
    "\n",
    "1. **ArcSplitter Agent** - Analyzes story structure and determines arc boundaries\n",
    "2. **WikiPlanner Agent** - Plans wiki structure and article organization  \n",
    "3. **ArticleWriter Agent** - Generates actual wiki article content\n",
    "4. **GeneralSummarizer Agent** - Creates summaries of various content types\n",
    "5. **ChapterBacklinker Agent** - Creates bidirectional links between chapters and articles\n",
    "6. **WikiGenOrchestrator** - Coordinates the complete workflow\n",
    "\n",
    "Each agent demonstrates the BaseAgent pattern with different default models to show architectural flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Setup\n",
    "\n",
    "Make sure the Portkey Gateway is running to use the LLM Service:\n",
    "\n",
    "```bash\n",
    "docker run \\\n",
    "  --name portkey-gateway \\\n",
    "  -p 8787:8787 \\\n",
    "  portkeyai/gateway:latest\n",
    "```\n",
    "\n",
    "The following cells will:\n",
    "- use the Portkey Gateway to test the LLM Service\n",
    "- initialize the LLM Service\n",
    "- import the WikiGen workflow agents\n",
    "- load a test story from the `tests/resources/pokemon_amber/story` directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Added unified Story model imports\n"
     ]
    }
   ],
   "source": [
    "# Additional imports for unified Story model\n",
    "from src.schemas.story import Story, Chapter\n",
    "\n",
    "print(\"âœ… Added unified Story model imports\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ WikiGen Agent Workflow Testing Environment\n",
      "============================================================\n",
      "Current working directory: /home/jimnix/gitrepos/shuscribe/backend/notebooks\n",
      "Database mode: IN-MEMORY\n",
      "Portkey Gateway: http://localhost:8787/v1\n",
      "Autoreload enabled. Changes to .py files in src/ will be reloaded.\n",
      "\n",
      "ğŸ’¡ This notebook tests WikiGen agents with real LLM calls.\n",
      "   Each agent can use different models to demonstrate flexibility.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Configuration\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import logging\n",
    "from uuid import uuid4\n",
    "from typing import Dict, Any, List, cast\n",
    "\n",
    "# Set environment to skip database for testing\n",
    "os.environ[\"SKIP_DATABASE\"] = \"true\"\n",
    "os.environ[\"PORTKEY_BASE_URL\"] = \"http://localhost:8787/v1\"  # Default Portkey Gateway\n",
    "\n",
    "# Add the backend/src directory to sys.path\n",
    "notebook_dir = Path.cwd()\n",
    "if (notebook_dir / 'src').is_dir() and (notebook_dir / 'pyproject.toml').is_file():\n",
    "    # This means we're likely in the backend/ directory itself\n",
    "    sys.path.insert(0, str(notebook_dir / 'src'))\n",
    "elif (notebook_dir.parent / 'src').is_dir() and (notebook_dir.parent / 'pyproject.toml').is_file():\n",
    "    # This means we're likely in the backend/notebooks/ directory\n",
    "    sys.path.insert(0, str(notebook_dir.parent / 'src'))\n",
    "else:\n",
    "    print(\"Warning: Could not automatically add 'src/' to Python path.\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "# Reduce noise from third-party loggers\n",
    "logging.getLogger('httpx').setLevel(logging.WARNING)\n",
    "logging.getLogger('uvicorn.access').setLevel(logging.WARNING)\n",
    "\n",
    "print(\"ğŸš€ WikiGen Agent Workflow Testing Environment\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Database mode: {'IN-MEMORY' if os.environ.get('SKIP_DATABASE') == 'true' else 'SUPABASE'}\")\n",
    "print(f\"Portkey Gateway: {os.environ.get('PORTKEY_BASE_URL', 'Not configured')}\")\n",
    "print(\"Autoreload enabled. Changes to .py files in src/ will be reloaded.\")\n",
    "print(\"\\nğŸ’¡ This notebook tests WikiGen agents with real LLM calls.\")\n",
    "print(\"   Each agent can use different models to demonstrate flexibility.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-29 19:27:56,119 - src.config - INFO - Pydantic Settings 'extra' mode set to: 'ignore' for environment: 'development'\n",
      "âœ… Modules imported successfully.\n",
      "\n",
      "--- Current Settings ---\n",
      "DEBUG: True\n",
      "ENVIRONMENT: development\n",
      "SKIP_DATABASE: True\n",
      "PORTKEY_BASE_URL: http://localhost:8787/v1\n",
      "DATABASE_MODE: In-Memory (Supabase skipped)\n",
      "------------------------\n",
      "\n",
      "ğŸ”§ Import Summary:\n",
      "âœ… LLMService - Ready for testing\n",
      "âœ… Repository Factory - Automatic in-memory/Supabase switching\n",
      "âœ… Pydantic Models - Type-safe user schemas\n",
      "âœ… Encryption - API key encryption/decryption\n",
      "âœ… Supabase Connection - Available when SKIP_DATABASE=false\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Modules (Updated for Supabase)\n",
    "from src.config import settings\n",
    "from src.services.llm.llm_service import LLMService\n",
    "from src.database.repositories import get_user_repository, get_story_repository\n",
    "from src.schemas.llm.models import LLMMessage, LLMResponse, ThinkingEffort\n",
    "from src.core.story_loading import StoryLoaderFactory\n",
    "from src.core.encryption import encrypt_api_key  # \n",
    "from dotenv import dotenv_values\n",
    "\n",
    "\n",
    "# WikiGen agent imports\n",
    "from src.agents.wikigen import (\n",
    "    WikiGenOrchestrator,\n",
    "    ArcSplitterAgent,\n",
    "    WikiPlannerAgent,\n",
    "    ArticleWriterAgent,\n",
    "    GeneralSummarizerAgent,\n",
    "    ChapterBacklinkerAgent\n",
    ")\n",
    "\n",
    "print(\"âœ… Modules imported successfully.\")\n",
    "\n",
    "# Display current settings\n",
    "print(\"\\n--- Current Settings ---\")\n",
    "print(f\"DEBUG: {settings.DEBUG}\")\n",
    "print(f\"ENVIRONMENT: {settings.ENVIRONMENT}\")\n",
    "print(f\"SKIP_DATABASE: {settings.SKIP_DATABASE}\")\n",
    "print(f\"PORTKEY_BASE_URL: {settings.PORTKEY_BASE_URL}\")\n",
    "if not settings.SKIP_DATABASE:\n",
    "    print(f\"SUPABASE_URL: {settings.SUPABASE_URL}\")\n",
    "    print(f\"SUPABASE_KEY: {'***' + settings.SUPABASE_KEY[-4:] if len(settings.SUPABASE_KEY) > 4 else 'Not set'}\")\n",
    "else:\n",
    "    print(\"DATABASE_MODE: In-Memory (Supabase skipped)\")\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"\\nğŸ”§ Import Summary:\")\n",
    "print(\"âœ… LLMService - Ready for testing\")\n",
    "print(\"âœ… Repository Factory - Automatic in-memory/Supabase switching\") \n",
    "print(\"âœ… Pydantic Models - Type-safe user schemas\")\n",
    "print(\"âœ… Encryption - API key encryption/decryption\")  # Updated\n",
    "print(\"âœ… Supabase Connection - Available when SKIP_DATABASE=false\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Initializing LLM Service...\n",
      "âœ… LLM Service initialized successfully!\n",
      "ğŸ“ Repository type: InMemoryUserRepository\n",
      "ğŸ›¡ï¸  Database mode: In-Memory\n",
      "\n",
      "ğŸ’¡ Running in database-free mode:\n",
      "   â€¢ Perfect for testing with direct API keys\n",
      "   â€¢ No Supabase setup required\n",
      "   â€¢ User API keys stored in memory only\n",
      "\n",
      "ğŸ”‘ Loading and storing encrypted API keys...\n",
      "ğŸ‘¤ Created test user: test@example.com (ID: 99d4f6d3-4138-4a6f-9363-4eb90d51a3fb)\n",
      "   ğŸ” Stored and encrypted OpenAI API key\n",
      "   ğŸ” Stored and encrypted Google API key\n",
      "   ğŸ” Stored and encrypted Anthropic API key\n",
      "âœ… Stored 3 encrypted API keys in repository\n",
      "ğŸ“‹ Available providers: OpenAI, Google, Anthropic\n",
      "\n",
      "ğŸ¯ Ready for testing!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize LLM Service and Store Encrypted API Keys\n",
    "\n",
    "print(\"ğŸš€ Initializing LLM Service...\")\n",
    "\n",
    "# The factory automatically chooses in-memory or Supabase based on SKIP_DATABASE\n",
    "llm_service = LLMService(user_repository=get_user_repository())\n",
    "\n",
    "# Ensure repository is available\n",
    "if not llm_service.user_repository:\n",
    "    raise RuntimeError(\"Failed to initialize user repository\")\n",
    "\n",
    "print(\"âœ… LLM Service initialized successfully!\")\n",
    "print(f\"ğŸ“ Repository type: {type(llm_service.user_repository).__name__}\")\n",
    "print(f\"ğŸ›¡ï¸  Database mode: {'In-Memory' if settings.SKIP_DATABASE else 'Supabase'}\")\n",
    "\n",
    "if settings.SKIP_DATABASE:\n",
    "    print(\"\\nğŸ’¡ Running in database-free mode:\")\n",
    "    print(\"   â€¢ Perfect for testing with direct API keys\")\n",
    "    print(\"   â€¢ No Supabase setup required\")\n",
    "    print(\"   â€¢ User API keys stored in memory only\")\n",
    "else:\n",
    "    print(\"\\nğŸ—„ï¸  Connected to Supabase:\")\n",
    "    print(\"   â€¢ User API keys stored encrypted in database\")\n",
    "    print(\"   â€¢ Full multi-user support enabled\")\n",
    "    print(\"   â€¢ Row-level security active\")\n",
    "\n",
    "print(\"\\nğŸ”‘ Loading and storing encrypted API keys...\")\n",
    "\n",
    "# Load environment variables once\n",
    "env_values = dotenv_values()\n",
    "\n",
    "# Create a test user for API key storage\n",
    "TEST_USER_ID = uuid4()\n",
    "test_user = await llm_service.user_repository.create({\n",
    "    \"id\": TEST_USER_ID,\n",
    "    \"email\": \"test@example.com\",\n",
    "    \"name\": \"Test User\"\n",
    "})\n",
    "\n",
    "print(f\"ğŸ‘¤ Created test user: {test_user.email} (ID: {TEST_USER_ID})\")\n",
    "\n",
    "# Store API keys from environment in the repository (properly encrypted)\n",
    "stored_keys = 0\n",
    "available_providers = []\n",
    "for provider in LLMService.get_all_llm_providers():\n",
    "    provider_id = provider.provider_id\n",
    "    api_key = env_values.get(f\"{provider_id.upper()}_API_KEY\")\n",
    "    \n",
    "    if api_key:\n",
    "        # Properly encrypt the API key before storing\n",
    "        encrypted_key = encrypt_api_key(api_key)\n",
    "        \n",
    "        await llm_service.user_repository.store_api_key(\n",
    "            user_id=TEST_USER_ID,\n",
    "            provider=provider_id,\n",
    "            encrypted_key=encrypted_key,  # Now properly encrypted\n",
    "            validation_status=\"pending\"\n",
    "        )\n",
    "        stored_keys += 1\n",
    "        available_providers.append(provider.display_name)\n",
    "        print(f\"   ğŸ” Stored and encrypted {provider.display_name} API key\")\n",
    "\n",
    "print(f\"âœ… Stored {stored_keys} encrypted API keys in repository\")\n",
    "if available_providers:\n",
    "    print(f\"ğŸ“‹ Available providers: {', '.join(available_providers)}\")\n",
    "print(\"\\nğŸ¯ Ready for testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Initializing Services and Loading Test Story...\n",
      "============================================================\n",
      "\n",
      "ğŸ“– Loading Test Story...\n",
      "âœ… Loaded: Pokemon: Ambertwo\n",
      "   Author: ChronicImmortality\n",
      "   Chapters: 8\n",
      "   Genres: Drama, Action, Adventure, Fantasy\n",
      "   Stored with ID: d6b0d4ce-a257-43fd-922d-2ce0cae543e7\n",
      "\n",
      "ğŸ“Š Test Data Summary:\n",
      "   Total characters: 104,667\n",
      "   First chapter: [Chapter 1] Truck-kun Strikes Again\n",
      "   Last chapter: [Chapter 8] Start of an Unpaid Side Quest\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load Test Story\n",
    "\n",
    "print(\"ğŸš€ Initializing Services and Loading Test Story...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "STORY_REPO = get_story_repository()\n",
    "\n",
    "print(\"\\nğŸ“– Loading Test Story...\")\n",
    "story_directory_path = Path(\"../tests/resources/pokemon_amber/story\")\n",
    "\n",
    "try:\n",
    "    input_story = StoryLoaderFactory.load_story(story_directory_path)\n",
    "    print(f\"âœ… Loaded: {input_story.title}\")\n",
    "    print(f\"   Author: {input_story.author}\")\n",
    "    print(f\"   Chapters: {input_story.total_chapters}\")\n",
    "    print(f\"   Genres: {', '.join(input_story.genres)}\")\n",
    "    \n",
    "    # Store in repository for testing\n",
    "    stored_story = await STORY_REPO.store_story(input_story, TEST_USER_ID)\n",
    "    AMBER_STORY_ID = stored_story.id\n",
    "    print(f\"   Stored with ID: {AMBER_STORY_ID}\")\n",
    "    \n",
    "    # Prepare story content for agent testing\n",
    "    story_content = \"\\n\\n\".join([\n",
    "        f\"# {chapter.title}\\n{chapter.content}\" \n",
    "        for chapter in input_story.chapters\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Test Data Summary:\")\n",
    "    print(f\"   Total characters: {len(story_content):,}\")\n",
    "    print(f\"   First chapter: {input_story.chapters[0].title}\")\n",
    "    print(f\"   Last chapter: {input_story.chapters[-1].title}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading story: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run individual agents\n",
    "\n",
    "## ğŸ“‹ WikiGen Agents\n",
    "\n",
    "1. **ArcSplitter Agent** - Analyzes story structure and determines arc boundaries\n",
    "2. **WikiPlanner Agent** - Plans wiki structure and article organization  \n",
    "3. **ArticleWriter Agent** - Generates actual wiki article content\n",
    "4. **GeneralSummarizer Agent** - Creates summaries of various content types\n",
    "5. **ChapterBacklinker Agent** - Creates bidirectional links between chapters and articles\n",
    "6. **WikiGenOrchestrator** - Coordinates the complete workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArcSplitter Agent - Streaming Analysis\n",
    "\n",
    "**ğŸ”„ Single LLM Call with Real-time Streaming!**\n",
    "\n",
    "The ArcSplitter agent now supports **streaming analysis** that provides real-time feedback while accumulating the final structured result. This approach uses **only one LLM call** for both user experience and final parsing.\n",
    "\n",
    "- âš¡ **Real-time Feedback** - See analysis progress as it happens\n",
    "- ğŸš€ **Single LLM Call** - No wasteful duplicate API calls  \n",
    "- ğŸ“Š **Live Updates** - Stream response chunks as they're generated\n",
    "- ğŸ¯ **Smart Accumulation** - Parse final accumulated result into structured data\n",
    "- ğŸ’° **Cost Efficient** - One call gives you both streaming UX and structured output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Testing ArcSplitter Agent - NEW STREAMING ARCHITECTURE\n",
      "============================================================\n",
      "This demonstrates the new clean separation of concerns:\n",
      "ğŸ“¡ Streaming: Raw LLM responses with proper chunk type labels\n",
      "ğŸ¯ State Management: Internal accumulation and parsing\n",
      "ğŸ”— Result Access: Clean final result via get_final_result()\n",
      "ğŸ“Š Story: Pokemon: Ambertwo (8 chapters)\n",
      "\n",
      "âš¡ Starting streaming analysis...\n",
      "ğŸ“¡ Live stream output (by chunk type):\n",
      "----------------------------------------\n",
      "2025-06-29 19:33:17,408 - src.agents.wikigen.arc_splitter - INFO - ğŸ”„ Starting new analysis: 1f2473ae-c4ff-49d9-9ad0-b9fc60181c02\n",
      "2025-06-29 19:33:17,409 - src.agents.wikigen.arc_splitter - INFO - ğŸ“ Model Context Window: 1,048,576 tokens\n",
      "2025-06-29 19:33:17,409 - src.agents.wikigen.arc_splitter - INFO - ğŸ“ Chunk Limit: 1,043,576 tokens (after 5,000 overhead)\n",
      "2025-06-29 19:33:17,410 - src.agents.wikigen.arc_splitter - INFO - ğŸ” ArcSplitter Analysis Starting:\n",
      "2025-06-29 19:33:17,410 - src.agents.wikigen.arc_splitter - INFO -    ğŸ“– Story: Pokemon: Ambertwo\n",
      "2025-06-29 19:33:17,411 - src.agents.wikigen.arc_splitter - INFO -    ğŸ“Š Chapters: 8, Words: 17108\n",
      "2025-06-29 19:33:17,412 - src.agents.wikigen.arc_splitter - INFO -    ğŸ§® Total tokens: 24227, Chunk limit: 1043576\n",
      "2025-06-29 19:33:17,413 - src.agents.wikigen.arc_splitter - INFO -    ğŸ“ Short story: False\n",
      "2025-06-29 19:33:17,414 - src.agents.wikigen.arc_splitter - INFO - ğŸ”„ Processing window 1: chapters 1-8\n",
      "2025-06-29 19:33:17,414 - src.agents.wikigen.arc_splitter - INFO -    ğŸ§® Chunk tokens: 24227, Final: True\n",
      "2025-06-29 19:33:17,416 - src.agents.wikigen.arc_splitter - INFO -    ğŸ¤– Making LLM call for window 1...\n",
      "2025-06-29 19:33:17,417 - src.services.llm.llm_service - INFO - Using database API key for provider=google, model=gemini-2.5-flash-lite-preview-06-17, user=99d4f6d3-4138-4a6f-9363-4eb90d51a3fb\n",
      "2025-06-29 19:33:17,443 - src.services.llm.llm_service - INFO - Set strict_open_ai_compliance=False for thinking mode\n",
      "2025-06-29 19:33:17,444 - src.services.llm.llm_service - INFO - Model gemini-2.5-flash-lite-preview-06-17 supports structured output - using response_format parameter\n",
      "2025-06-29 19:33:17,444 - src.services.llm.llm_service - INFO - Using simplified schema for Google Gemini (removed validation constraints)\n",
      "2025-06-29 19:33:17,445 - src.services.llm.llm_service - INFO - Making LLM request: provider=google, model=gemini-2.5-flash-lite-preview-06-17, gateway=http://localhost:8787/v1, streaming=True\n",
      "2025-06-29 19:33:17,446 - src.services.llm.llm_service - INFO - Calculated thinking budget: 3686 tokens for low effort on google/gemini-2.5-flash-lite-preview-06-17\n",
      "2025-06-29 19:33:17,446 - src.services.llm.llm_service - INFO - Using thinking with 3686 budget tokens for Google model gemini-2.5-flash-lite-preview-06-17\n",
      "[THINKING] Chunk ? (1-8): 395 chars\n",
      "  ğŸ¤” Thinking: 395 chars\n",
      "[THINKING] Chunk ? (1-8): 464 chars\n",
      "  ğŸ¤” Thinking: 464 chars\n",
      "[THINKING] Chunk ? (1-8): 473 chars\n",
      "  ğŸ¤” Thinking: 473 chars\n",
      "[THINKING] Chunk ? (1-8): 451 chars\n",
      "  ğŸ¤” Thinking: 451 chars\n",
      "[THINKING] Chunk ? (1-8): 571 chars\n",
      "  ğŸ¤” Thinking: 571 chars\n",
      "[THINKING] Chunk ? (1-8): 606 chars\n",
      "  ğŸ¤” Thinking: 606 chars\n",
      "[THINKING] Chunk ? (1-8): 443 chars\n",
      "  ğŸ¤” Thinking: 443 chars\n",
      "[THINKING] Chunk ? (1-8): 399 chars\n",
      "  ğŸ¤” Thinking: 399 chars\n",
      "[THINKING] Chunk ? (1-8): 398 chars\n",
      "  ğŸ¤” Thinking: 398 chars\n",
      "[THINKING] Chunk ? (1-8): 409 chars\n",
      "  ğŸ¤” Thinking: 409 chars\n",
      "[THINKING] Chunk ? (1-8): 856 chars\n",
      "  ğŸ¤” Thinking: 856 chars\n",
      "[THINKING] Chunk ? (1-8): 394 chars\n",
      "  ğŸ¤” Thinking: 394 chars\n",
      "[THINKING] Chunk ? (1-8): 233 chars\n",
      "  ğŸ¤” Thinking: 233 chars\n",
      "[THINKING] Chunk ? (1-8): 384 chars\n",
      "  ğŸ¤” Thinking: 384 chars\n",
      "[THINKING] Chunk ? (1-8): 327 chars\n",
      "  ğŸ¤” Thinking: 327 chars\n",
      "[CONTENT] Chunk ? (1-8): 461 chars\n",
      "  ğŸ“ Content preview: I'm currently solidifying the final arc structure and making sure the information presented is the m...\n",
      "[THINKING] Chunk ? (1-8): 233 chars\n",
      "  ğŸ¤” Thinking: 233 chars\n",
      "[THINKING] Chunk ? (1-8): 384 chars\n",
      "  ğŸ¤” Thinking: 384 chars\n",
      "[THINKING] Chunk ? (1-8): 233 chars\n",
      "  ğŸ¤” Thinking: 233 chars\n",
      "[THINKING] Chunk ? (1-8): 233 chars\n",
      "  ğŸ¤” Thinking: 233 chars\n",
      "[THINKING] Chunk ? (1-8): 384 chars\n",
      "  ğŸ¤” Thinking: 384 chars\n",
      "[THINKING] Chunk ? (1-8): 520 chars\n",
      "  ğŸ¤” Thinking: 520 chars\n",
      "[CONTENT] Chunk ? (1-8): 169 chars\n",
      "\\n{\\n  \"arc_strategy\": \"The arc division strategy prioritizes the core principle of fewer, more com...\n",
      "[CONTENT] Chunk ? (1-8): 280 chars\n",
      "  ğŸ“ Content preview:  chapters provided, the focus is on identifying the most pivotal narrative transitions. The story be...\n",
      "[CONTENT] Chunk ? (1-8): 240 chars\n",
      "  ğŸ“ Content preview:  (Chapters 1-6), covers the initial phase of the protagonist's awakening in the Pokemon world, her a...\n",
      "[CONTENT] Chunk ? (1-8): 239 chars\n",
      "  ğŸ“ Content preview: two. This arc establishes the core premise and conflict. Arc 2, \\\"Celadon's Underbelly\\\" (Chapters 7...\n",
      "[CONTENT] Chunk ? (1-8): 319 chars\n",
      "  ğŸ“ Content preview:  This arc is designed to be broad enough to encompass future plot developments related to Team Rocke...\n",
      "[CONTENT] Chunk ? (1-8): 153 chars\n",
      "  ğŸ“ Content preview:  at this early stage, adhering to the \\\"default to fewer arcs\\\" guideline.\",\\n  \"arcs\": [\\n    {\\n     ...\n",
      "[CONTENT] Chunk ? (1-8): 266 chars\n",
      "  ğŸ“ Content preview:  \"Reincarnation after death, escape from a lab during Mewtwo's rampage, journey to Celadon City, acq...\n",
      "[CONTENT] Chunk ? (1-8): 228 chars\n",
      "  ğŸ“ Content preview:  about her cloned origins and Team Rocket's involvement from Dr. Fuji's perspective, meeting Giovann...\n",
      "[CONTENT] Chunk ? (1-8): 252 chars\n",
      "  ğŸ“ Content preview: summary\": \"The protagonist dies and is reborn into the Pokemon world as Amber Fuji, grappling with a...\n",
      "[CONTENT] Chunk ? (1-8): 394 chars\n",
      "  ğŸ“ Content preview:  Ditto, and the shocking discovery of her origins as a clone and the involvement of Team Rocket in h...\n",
      "[CONTENT] Chunk ? (1-8): 250 chars\n",
      "  ğŸ“ Content preview:  transforming to help identify the culprit, meeting Erika and discussing the potential use of Oddish...\n",
      "[CONTENT] Chunk ? (1-8): 294 chars\n",
      "  ğŸ“ Content preview: \": \"Following the revelations of her past, the protagonist is drawn into a local investigation withi...\n",
      "[CONTENT] Chunk ? (1-8): 460 chars\n",
      "  ğŸ“ Content preview:  corporate espionage related to Pokemon ingredients, setting the stage for further adventures and co...\n",
      "[CONTENT] Chunk ? (1-8): 273 chars\n",
      "  ğŸ“ Content preview:  Pokemon and Team Rocket's larger operations. The established world-building elementsâ€”cloning, genet...\n",
      "[CONTENT] Chunk ? (1-8): 287 chars\n",
      "  ğŸ“ Content preview:  content could include exploration of other regions, encounters with iconic Pokemon characters, deep...\n",
      "[CONTENT] Chunk ? (1-8): 253 chars\n",
      "  ğŸ“ Content preview:  a wide range of future developments without requiring immediate re-division.\",\\n  \"story_prediction\"...\n",
      "[CONTENT] Chunk ? (1-8): 289 chars\n",
      "  ğŸ“ Content preview: . Future plotlines will likely involve her mastering her abilities as a trainer, exploring different...\n",
      "[CONTENT] Chunk ? (1-8): 287 chars\n",
      "  ğŸ“ Content preview:  the world will challenge her assumptions. Team Rocket's pursuit of powerful Pokemon and their explo...\n",
      "[CONTENT] Chunk ? (1-8): 208 chars\n",
      "  ğŸ“ Content preview:  father, and Team Rocket operative will likely lead to moral dilemmas and potential betrayals or all...\n",
      "2025-06-29 19:33:39,930 - src.agents.wikigen.arc_splitter - INFO -    ğŸ“¡ Window 1: 41 streaming responses\n",
      "2025-06-29 19:33:39,931 - src.agents.wikigen.arc_splitter - INFO -    âœ… Window 1: Parsed 2 arcs\n",
      "2025-06-29 19:33:39,932 - src.agents.wikigen.arc_splitter - INFO - âœ… Streaming completed: 1 windows processed\n",
      "----------------------------------------\n",
      "âœ… Streaming completed!\n",
      "ğŸ“Š Chunk counts: {<ChunkType.THINKING: 'thinking'>: 21, <ChunkType.CONTENT: 'content'>: 20, <ChunkType.UNKNOWN: 'unknown'>: 0}\n",
      "ğŸ“ Total content characters: 5602\n",
      "\n",
      "ğŸ” Internal Chunk Processing Summary:\n",
      "  Chunk 1: 1-8\n",
      "    ğŸ“ Accumulated: T=8790, C=5602, U=0 chars\n",
      "    âœ… Parsed: 2 arcs\n",
      "\n",
      "ğŸ¯ Getting final result...\n",
      "2025-06-29 19:33:39,933 - src.agents.wikigen.arc_splitter - INFO -    â• Chunk 1: Added 2 arcs\n",
      "2025-06-29 19:33:39,933 - src.agents.wikigen.arc_splitter - INFO - ğŸ¯ Final result: 2 total arcs merged from 1 chunks\n",
      "âœ… Final result ready!\n",
      "ğŸ“– Total arcs generated: 2\n",
      "\n",
      "ğŸ›ï¸  Arc 1: Rebirth and Revelation\n",
      "   ğŸ“– Chapters: 1-6\n",
      "   ğŸ“ Summary: The protagonist dies and is reborn into the Pokemon world as Amber Fuji, grappling with a stolen ide...\n",
      "   ğŸ”’ Finalized: True\n",
      "\n",
      "ğŸ›ï¸  Arc 2: Celadon's Underbelly\n",
      "   ğŸ“– Chapters: 7-8\n",
      "   ğŸ“ Summary: Following the revelations of her past, the protagonist is drawn into a local investigation within Ce...\n",
      "   ğŸ”’ Finalized: True\n"
     ]
    }
   ],
   "source": [
    "# Cell: 4 Test ArcSplitter Agent - New Streaming Architecture\n",
    "\n",
    "print(\"\\nğŸ”„ Testing ArcSplitter Agent - NEW STREAMING ARCHITECTURE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This demonstrates the new clean separation of concerns:\")\n",
    "print(\"ğŸ“¡ Streaming: Raw LLM responses with proper chunk type labels\")\n",
    "print(\"ğŸ¯ State Management: Internal accumulation and parsing\")\n",
    "print(\"ğŸ”— Result Access: Clean final result via get_final_result()\")\n",
    "\n",
    "# provider = \"google\"  # Use Google for streaming demo    \n",
    "# api_key = AVAILABLE_PROVIDERS[provider]['api_key']\n",
    "# model = LLMService.get_default_test_model_name_for_provider(provider)\n",
    "# model = \"claude-sonnet-4-20250514\"\n",
    "# model = \"gemini-2.5-flash-lite-preview-06-17\"\n",
    "# model = \"o4-mini\"\n",
    "\n",
    "# print(f\"ğŸ”§ Streaming with: {provider} / {model}\")\n",
    "\n",
    "if AMBER_STORY_ID is not None:\n",
    "    STORY = await STORY_REPO.get_story(AMBER_STORY_ID)\n",
    "    print(f\"ğŸ“Š Story: {STORY.title} ({len(STORY.chapters)} chapters)\")\n",
    "\n",
    "try:\n",
    "    # Initialize the agent\n",
    "    arc_splitter_streaming = ArcSplitterAgent(\n",
    "        llm_service=llm_service,\n",
    "        # default_provider=provider,\n",
    "        # default_model=model,\n",
    "        temperature=0.7,\n",
    "        max_tokens=16000,\n",
    "        thinking=ThinkingEffort.LOW\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâš¡ Starting streaming analysis...\")\n",
    "    print(\"ğŸ“¡ Live stream output (by chunk type):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Import ChunkType for proper enum usage\n",
    "    from src.schemas.llm.models import ChunkType\n",
    "    \n",
    "    # Track streaming responses by type - Using enum constants\n",
    "    chunk_counts = {ChunkType.THINKING: 0, ChunkType.CONTENT: 0, ChunkType.UNKNOWN: 0}\n",
    "    total_content_chars = 0\n",
    "    \n",
    "    async for chunk in arc_splitter_streaming.analyze_story_streaming(\n",
    "        story=STORY,\n",
    "        user_id=TEST_USER_ID,\n",
    "    ):\n",
    "        # Use the enum directly - no need for .value\n",
    "        chunk_type = chunk.chunk_type\n",
    "        chunk_counts[chunk_type] += 1\n",
    "        \n",
    "        # Get metadata for debugging\n",
    "        metadata = chunk.metadata or {}\n",
    "        chunk_num = metadata.get(\"chunk_number\", \"?\")\n",
    "        chapters = metadata.get(\"chapters\", \"?\")\n",
    "        \n",
    "        # Show chunk info - use .value for display\n",
    "        print(f\"[{chunk_type.value.upper()}] Chunk {chunk_num} ({chapters}): {len(chunk.content)} chars\")\n",
    "        \n",
    "        # For CONTENT chunks, show a preview of the actual content\n",
    "        if chunk_type == ChunkType.CONTENT and chunk.content:\n",
    "            total_content_chars += len(chunk.content)\n",
    "            # Show first bit of content for CONTENT chunks\n",
    "            preview = chunk.content[:100].replace(\"\\n\", \"\\\\n\")\n",
    "            print(f\"  ğŸ“ Content preview: {preview}...\")\n",
    "        \n",
    "        # For THINKING chunks, just show that we got thinking\n",
    "        elif chunk_type == ChunkType.THINKING and chunk.content:\n",
    "            print(f\"  ğŸ¤” Thinking: {len(chunk.content)} chars\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"âœ… Streaming completed!\")\n",
    "    print(f\"ğŸ“Š Chunk counts: {chunk_counts}\")\n",
    "    print(f\"ğŸ“ Total content characters: {total_content_chars}\")\n",
    "    \n",
    "    # Get internal chunk processing details\n",
    "    chunk_results = arc_splitter_streaming.get_window_results()\n",
    "    print(f\"\\nğŸ” Internal Chunk Processing Summary:\")\n",
    "    for chunk_result in chunk_results:\n",
    "        print(f\"  Chunk {chunk_result.window_number}: {chunk_result.chapters_range}\")\n",
    "        raw = chunk_result.raw_content\n",
    "        print(f\"    ğŸ“ Accumulated: T={len(raw.thinking)}, C={len(raw.content)}, U={len(raw.unknown)} chars\")\n",
    "        if chunk_result.parsed_result:\n",
    "            print(f\"    âœ… Parsed: {len(chunk_result.parsed_result.arcs)} arcs\")\n",
    "        if chunk_result.error:\n",
    "            print(f\"    âŒ Error: {chunk_result.error}\")\n",
    "    \n",
    "    # Get the final merged result (no manual parsing needed!)\n",
    "    print(f\"\\nğŸ¯ Getting final result...\")\n",
    "    try:\n",
    "        final_result = arc_splitter_streaming.get_final_result()\n",
    "        \n",
    "        print(f\"âœ… Final result ready!\")\n",
    "        print(f\"ğŸ“– Total arcs generated: {len(final_result.arcs)}\")\n",
    "        \n",
    "        # Show all arcs\n",
    "        for i, arc in enumerate(final_result.arcs):\n",
    "            print(f\"\\nğŸ›ï¸  Arc {i+1}: {arc.title}\")\n",
    "            print(f\"   ğŸ“– Chapters: {arc.start_chapter}-{arc.end_chapter}\")\n",
    "            print(f\"   ğŸ“ Summary: {arc.summary[:100]}...\")\n",
    "            print(f\"   ğŸ”’ Finalized: {arc.is_finalized}\")\n",
    "            \n",
    "    except Exception as parse_error:\n",
    "        print(f\"âŒ Could not get final result: {parse_error}\")\n",
    "        print(\"ğŸ’¡ Check the chunk processing summary above for errors\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Streaming test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm currently solidifying the final arc structure and making sure the information presented is the most up-to-date and complete. Given that this is the concluding section, all arcs will have their `is_finalized` value set to `true` to indicate the completion of this initial structure. This approach is intended to provide a robust framework that can readily expand as the story grows in the future, encompassing the core themes and overarching plot threads.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "  \"arc_strategy\": \"The arc division strategy prioritizes the core principle of fewer, more comprehensive arcs to accommodate significant future growth. With only 8 chapters provided, the focus is on identifying the most pivotal narrative transitions. The story begins with a fundamental reset of the protagonist's existence and ends with a significant reveal about her origins and the overarching antagonists. Arc 1, \\\"Rebirth and Revelation\\\" (Chapters 1-6), covers the initial phase of the protagonist's awakening in the Pokemon world, her adaptation, early training, and the crucial exposition that reveals her true nature as a clone and the major players like Team Rocket and Mewtwo. This arc establishes the core premise and conflict. Arc 2, \\\"Celadon's Underbelly\\\" (Chapters 7-8), begins the next phase, focusing on immediate local challenges and investigations within Celadon City that hint at larger conspiracies. This arc is designed to be broad enough to encompass future plot developments related to Team Rocket's activities in the city and the protagonist's growing involvement in uncovering secrets. This conservative approach ensures that future content can be integrated seamlessly without necessitating further arc splitting at this early stage, adhering to the \\\"default to fewer arcs\\\" guideline.\",\n",
      "  \"arcs\": [\n",
      "    {\n",
      "      \"end_chapter\": 6,\n",
      "      \"id\": 1,\n",
      "      \"key_events\": \"Reincarnation after death, escape from a lab during Mewtwo's rampage, journey to Celadon City, acquiring Ditto, first real Pokemon battle, discovering the financial barrier to gym challenges, entering a restricted greenhouse and being caught by gym staff, learning about her cloned origins and Team Rocket's involvement from Dr. Fuji's perspective, meeting Giovanni, and understanding the scale of Team Rocket's operations and interest in powerful Pokemon.\",\n",
      "      \"start_chapter\": 1,\n",
      "      \"summary\": \"The protagonist dies and is reborn into the Pokemon world as Amber Fuji, grappling with a stolen identity and newfound abilities. This arc covers her escape from a destroyed lab, her journey to Celadon City, her first steps as a trainer with Ditto, and the shocking discovery of her origins as a clone and the involvement of Team Rocket in her creation and the world's power struggles.\",\n",
      "      \"title\": \"Rebirth and Revelation\",\n",
      "      \"is_finalized\": true\n",
      "    },\n",
      "    {\n",
      "      \"end_chapter\": 8,\n",
      "      \"id\": 2,\n",
      "      \"key_events\": \"Being questioned by gym security about the greenhouse incident, footage revealing a different thief, Ditto transforming to help identify the culprit, meeting Erika and discussing the potential use of Oddish in HP UP production, and initiating an investigation into item shops and illicit Pokemon ingredient trade.\",\n",
      "      \"start_chapter\": 7,\n",
      "      \"summary\": \"Following the revelations of her past, the protagonist is drawn into a local investigation within Celadon City concerning a mysterious Oddish theft. This arc sees her utilizing Ditto's transformation abilities to aid gym security, interacting with gym leader Erika, and uncovering potential corporate espionage related to Pokemon ingredients, setting the stage for further adventures and conflicts within the city.\",\n",
      "      \"title\": \"Celadon's Underbelly\",\n",
      "      \"is_finalized\": true\n",
      "    }\n",
      "  ],\n",
      "  \"growth_assessment\": \"This story has immense potential for growth, easily scaling 2-5x its current length. The narrative can expand to cover the protagonist's entire journey through the Pokemon world, from challenging Gym Leaders to confronting legendary Pokemon and Team Rocket's larger operations. The established world-building elementsâ€”cloning, genetic manipulation, Team Rocket's infrastructure, and the integration of Pokemon into societyâ€”provide a rich foundation for numerous subplots and overarching story arcs. Future content could include exploration of other regions, encounters with iconic Pokemon characters, deeper dives into the lore of Pokemon creation, and the development of the protagonist's unique skills and relationships. The current arc structure is designed to be flexible enough to absorb a wide range of future developments without requiring immediate re-division.\",\n",
      "  \"story_prediction\": \"The story is poised for a long-term narrative focused on the protagonist's journey of self-discovery and her role in combating Team Rocket's ambitions. Future plotlines will likely involve her mastering her abilities as a trainer, exploring different regions of the Pokemon world, and uncovering the secrets behind Mewtwo and other genetically engineered Pokemon. Her unique meta-knowledge will be a recurring advantage, but the reality of the world will challenge her assumptions. Team Rocket's pursuit of powerful Pokemon and their exploitation of Pokemon biology will drive central conflicts, potentially leading to direct confrontations with their leadership and research divisions. Dr. Fuji's complex role as a scientist, father, and Team Rocket operative will likely lead to moral dilemmas and potential betrayals or alliances. The protagonist's connection to Amber's mother, Delia, may also become a significant plot thread.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(chunk_results[0].raw_content.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"story_prediction\": \"The story is poised for a long-term narrative focused on the protagonist's journey of self-discovery and her role in combating Team Rocket's ambitions. Future plotlines will likely involve her mastering her abilities as a trainer, exploring different regions of the Pokemon world, and uncovering the secrets behind Mewtwo and other genetically engineered Pokemon. Her unique meta-knowledge will be a recurring advantage, but the reality of the world will challenge her assumptions. Team Rocket's pursuit of powerful Pokemon and their exploitation of Pokemon biology will drive central conflicts, potentially leading to direct confrontations with their leadership and research divisions. Dr. Fuji's complex role as a scientist, father, and Team Rocket operative will likely lead to moral dilemmas and potential betrayals or alliances. The protagonist's connection to Amber's mother, Delia, may also become a significant plot thread.\",\n",
      "  \"growth_assessment\": \"This story has immense potential for growth, easily scaling 2-5x its current length. The narrative can expand to cover the protagonist's entire journey through the Pokemon world, from challenging Gym Leaders to confronting legendary Pokemon and Team Rocket's larger operations. The established world-building elementsâ€”cloning, genetic manipulation, Team Rocket's infrastructure, and the integration of Pokemon into societyâ€”provide a rich foundation for numerous subplots and overarching story arcs. Future content could include exploration of other regions, encounters with iconic Pokemon characters, deeper dives into the lore of Pokemon creation, and the development of the protagonist's unique skills and relationships. The current arc structure is designed to be flexible enough to absorb a wide range of future developments without requiring immediate re-division.\",\n",
      "  \"arc_strategy\": \"The arc division strategy prioritizes the core principle of fewer, more comprehensive arcs to accommodate significant future growth. With only 8 chapters provided, the focus is on identifying the most pivotal narrative transitions. The story begins with a fundamental reset of the protagonist's existence and ends with a significant reveal about her origins and the overarching antagonists. Arc 1, \\\"Rebirth and Revelation\\\" (Chapters 1-6), covers the initial phase of the protagonist's awakening in the Pokemon world, her adaptation, early training, and the crucial exposition that reveals her true nature as a clone and the major players like Team Rocket and Mewtwo. This arc establishes the core premise and conflict. Arc 2, \\\"Celadon's Underbelly\\\" (Chapters 7-8), begins the next phase, focusing on immediate local challenges and investigations within Celadon City that hint at larger conspiracies. This arc is designed to be broad enough to encompass future plot developments related to Team Rocket's activities in the city and the protagonist's growing involvement in uncovering secrets. This conservative approach ensures that future content can be integrated seamlessly without necessitating further arc splitting at this early stage, adhering to the \\\"default to fewer arcs\\\" guideline.\",\n",
      "  \"arcs\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"title\": \"Rebirth and Revelation\",\n",
      "      \"start_chapter\": 1,\n",
      "      \"end_chapter\": 6,\n",
      "      \"summary\": \"The protagonist dies and is reborn into the Pokemon world as Amber Fuji, grappling with a stolen identity and newfound abilities. This arc covers her escape from a destroyed lab, her journey to Celadon City, her first steps as a trainer with Ditto, and the shocking discovery of her origins as a clone and the involvement of Team Rocket in her creation and the world's power struggles.\",\n",
      "      \"key_events\": \"Reincarnation after death, escape from a lab during Mewtwo's rampage, journey to Celadon City, acquiring Ditto, first real Pokemon battle, discovering the financial barrier to gym challenges, entering a restricted greenhouse and being caught by gym staff, learning about her cloned origins and Team Rocket's involvement from Dr. Fuji's perspective, meeting Giovanni, and understanding the scale of Team Rocket's operations and interest in powerful Pokemon.\",\n",
      "      \"is_finalized\": true\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"title\": \"Celadon's Underbelly\",\n",
      "      \"start_chapter\": 7,\n",
      "      \"end_chapter\": 8,\n",
      "      \"summary\": \"Following the revelations of her past, the protagonist is drawn into a local investigation within Celadon City concerning a mysterious Oddish theft. This arc sees her utilizing Ditto's transformation abilities to aid gym security, interacting with gym leader Erika, and uncovering potential corporate espionage related to Pokemon ingredients, setting the stage for further adventures and conflicts within the city.\",\n",
      "      \"key_events\": \"Being questioned by gym security about the greenhouse incident, footage revealing a different thief, Ditto transforming to help identify the culprit, meeting Erika and discussing the potential use of Oddish in HP UP production, and initiating an investigation into item shops and illicit Pokemon ingredient trade.\",\n",
      "      \"is_finalized\": true\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(final_result.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiPlanner Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArticleWriterAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneralSummarizerAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiGenOrchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
