{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Pipeline Interactive Testing\n",
    "\n",
    "This notebook provides an environment to interactively test and debug components of the ShuScribe LLM pipeline, including the `LLMService`, entity extraction, and wiki generation logic.\n",
    "\n",
    "## Make sure the Portkey Gateway is running to use an LLM Service\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  --name portkey-gateway \\\n",
    "  -p 8787:8787 \\\n",
    "  portkeyai/gateway:latest\n",
    "```\n",
    "\n",
    "## ‚öôÔ∏è Setup and Autoreload\n",
    "\n",
    "The `%load_ext autoreload` and `%autoreload 2` magic commands ensure that any changes you make to your Python source files (`.py`) in `src/` are automatically reloaded in the notebook without needing to restart the kernel. This is crucial for rapid iteration.\n",
    "\n",
    "We also configure basic logging for visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/jimnix/gitrepos/shuscribe/backend/notebooks\n",
      "sys.path: ['/home/jimnix/gitrepos/shuscribe/backend/src', '/home/jimnix/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python312.zip', '/home/jimnix/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12', '/home/jimnix/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/lib-dynload', '', '/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages', '/home/jimnix/gitrepos/shuscribe/backend']\n",
      "Autoreload enabled. Changes to .py files in src/ will be reloaded.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import logging\n",
    "from uuid import uuid4\n",
    "\n",
    "# Add the backend/src directory to sys.path so we can import our modules\n",
    "# This assumes you are running the notebook from the `backend/` directory or VS Code multi-root\n",
    "notebook_dir = Path.cwd()\n",
    "if (notebook_dir / 'src').is_dir() and (notebook_dir / 'pyproject.toml').is_file():\n",
    "    # This means we're likely in the backend/ directory itself\n",
    "    sys.path.insert(0, str(notebook_dir / 'src'))\n",
    "elif (notebook_dir.parent / 'src').is_dir() and (notebook_dir.parent / 'pyproject.toml').is_file():\n",
    "    # This means we're likely in the backend/notebooks/ directory\n",
    "    sys.path.insert(0, str(notebook_dir.parent / 'src'))\n",
    "else:\n",
    "    print(\"Warning: Could not automatically add 'src/' to Python path. Please ensure your current directory allows imports from src/\")\n",
    "\n",
    "# Configure logging for better output\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "logging.getLogger('sqlalchemy.engine').setLevel(logging.WARNING)\n",
    "logging.getLogger('uvicorn.access').setLevel(logging.WARNING)\n",
    "logging.getLogger('shuscribe').setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"sys.path: {sys.path}\")\n",
    "print(\"Autoreload enabled. Changes to .py files in src/ will be reloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Import Modules\n",
    "\n",
    "Import necessary modules from your `src/` directory. This is where you'll bring in your `Settings`, `LLMService`, `UserRepository`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-27 01:40:38,863 - src.config - INFO - Pydantic Settings 'extra' mode set to: 'ignore' for environment: 'development'\n",
      "2025-06-27 01:40:40,022 - src.database.connection - WARNING - Database connection skipped due to SKIP_DATABASE setting.\n",
      "Modules imported successfully.\n",
      "\n",
      "--- Current Settings ---\n",
      "DEBUG: True\n",
      "ENVIRONMENT: development\n",
      "DATABASE_URL: postgresql+asyncpg://postgres:password@localhost:5432/shuscribe\n",
      "SKIP_DATABASE: True\n",
      "PORTKEY_BASE_URL: http://localhost:8787/v1\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.config import settings\n",
    "from src.services.llm.llm_service import LLMService\n",
    "from src.database.repositories.user import UserRepository\n",
    "from src.database.connection import get_db_session, engine, AsyncSessionLocal, init_db # Import all for flexibility\n",
    "from src.schemas.llm.models import LLMMessage, LLMResponse\n",
    "from src.core.exceptions import ShuScribeException\n",
    "from dotenv import dotenv_values # NEW: For loading test LLM keys\n",
    "\n",
    "print(\"Modules imported successfully.\")\n",
    "\n",
    "# Display current settings\n",
    "print(\"\\n--- Current Settings ---\")\n",
    "print(f\"DEBUG: {settings.DEBUG}\")\n",
    "print(f\"ENVIRONMENT: {settings.ENVIRONMENT}\")\n",
    "print(f\"DATABASE_URL: {settings.DATABASE_URL}\")\n",
    "print(f\"SKIP_DATABASE: {settings.SKIP_DATABASE}\")\n",
    "print(f\"PORTKEY_BASE_URL: {settings.PORTKEY_BASE_URL}\")\n",
    "print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Database & Service Initialization\n",
    "\n",
    "We need to initialize the database connection and the services. The `LLMService` requires a `UserRepository` instance, which in turn requires an `AsyncSession`. If `SKIP_DATABASE` is `True` in your `.env`, database-dependent operations will raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database is skipped. LLMService features requiring DB access (like fetching user API keys) will not work correctly.\n",
      "LLMService initialized with a mock UserRepository.\n"
     ]
    }
   ],
   "source": [
    "user_repo: UserRepository = None\n",
    "llm_service: LLMService = None\n",
    "\n",
    "async def initialize_services():\n",
    "    global user_repo, llm_service\n",
    "\n",
    "    if settings.SKIP_DATABASE:\n",
    "        print(\"Warning: Database is skipped. LLMService features requiring DB access (like fetching user API keys) will not work correctly.\")\n",
    "        # For very basic testing of LLMService's *interface* only, you might mock user_repo\n",
    "        # For full testing, set SKIP_DATABASE=false in your .env and ensure your DB is running.\n",
    "        class MockUserRepository:\n",
    "            async def get_api_key(self, user_id, provider):\n",
    "                # Return a dummy key or None, depending on what you're testing\n",
    "                print(\"MockUserRepository: get_api_key called. Returning None.\")\n",
    "                return None\n",
    "        user_repo = MockUserRepository()\n",
    "        llm_service = LLMService(user_repository=user_repo)\n",
    "        print(\"LLMService initialized with a mock UserRepository.\")\n",
    "        return\n",
    "\n",
    "    if not engine or not AsyncSessionLocal:\n",
    "        print(\"Error: Database engine or session local not initialized. Attempting init_db()...\")\n",
    "        try:\n",
    "            # This will run Base.metadata.create_all() for development setups\n",
    "            await init_db()\n",
    "        except ShuScribeException as e:\n",
    "            print(f\"Failed to initialize DB: {e.message}. Please ensure PostgreSQL is running and accessible.\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during DB initialization: {e}\")\n",
    "            return\n",
    "\n",
    "    # Get a DB session for the repo\n",
    "    db_session_gen = get_db_session()\n",
    "    try:\n",
    "        session = await anext(db_session_gen) # Get the session from the generator\n",
    "        user_repo = UserRepository(session=session)\n",
    "        llm_service = LLMService(user_repository=user_repo)\n",
    "        print(\"Database connection and LLMService initialized successfully.\")\n",
    "    except StopAsyncIteration:\n",
    "        print(\"Error: get_db_session did not yield a session. Database connection likely failed.\")\n",
    "    except ShuScribeException as e:\n",
    "        print(f\"Error initializing services: {e.message}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during service initialization: {e}\")\n",
    "    finally:\n",
    "        # The generator context manager handles closing the session, so no explicit session.close() here\n",
    "        pass # await db_session_gen.aclose() # If needed for explicit cleanup, but context manager handles it\n",
    "\n",
    "\n",
    "# Run the async initialization function\n",
    "await initialize_services()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë API Key Management Test\n",
    "\n",
    "Test the `validate_api_key` method of the `LLMService`. You will need to provide a real API key for a supported provider (e.g., OpenAI, Anthropic, Google).\n",
    "\n",
    "### Again, make sure the Portkey Gateway is running to use an LLM Service\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  --name portkey-gateway \\\n",
    "  -p 8787:8787 \\\n",
    "  portkeyai/gateway:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running LLM API Key Validation Tests ---\n",
      "  Validating Openai key with model 'gpt-4.1-mini'...\n",
      "2025-06-27 01:40:45,931 - httpx - INFO - HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "‚úÖ OpenAI: SUCCESS\n",
      "  Validating Anthropic key with model 'claude-3-5-haiku-latest'...\n",
      "2025-06-27 01:40:45,467 - httpx - INFO - HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "‚úÖ Anthropic: SUCCESS\n",
      "  Validating Google key with model 'gemini-2.5-flash'...\n",
      "2025-06-27 01:40:48,344 - httpx - INFO - HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "‚úÖ Google: SUCCESS\n",
      "\n",
      "============================================================\n",
      "--- Test Summary ---\n",
      "\n",
      "‚úÖ All configured LLM API key validation tests passed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: LLM API Key Validation Test (Refactored)\n",
    "import asyncio\n",
    "from dotenv import dotenv_values\n",
    "from src.core.llm.catalog import get_all_llm_providers, get_default_test_model_name_for_provider\n",
    "\n",
    "def get_api_key_from_env(provider_id: str, env: dict) -> str | None:\n",
    "    \"\"\"Constructs the env var name (e.g., 'OPENAI_API_KEY') and retrieves the key.\"\"\"\n",
    "    key_name = f\"{provider_id.upper()}_API_KEY\"\n",
    "    return env.get(key_name)\n",
    "\n",
    "async def test_provider_key(provider_id: str, llm_service: LLMService, env_values: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Tests API key validation for a single provider and returns a structured result.\n",
    "    \"\"\"\n",
    "    result = {\"provider\": provider_id, \"status\": \"SKIPPED\", \"message\": \"\"}\n",
    "    api_key = get_api_key_from_env(provider_id, env_values)\n",
    "    test_model = get_default_test_model_name_for_provider(provider_id)\n",
    "\n",
    "    if not api_key:\n",
    "        result[\"message\"] = f\"API key ({provider_id.upper()}_API_KEY) not found in .env\"\n",
    "        return result\n",
    "    \n",
    "    if not test_model:\n",
    "        result[\"message\"] = f\"Default test model not found in catalog\"\n",
    "        return result\n",
    "\n",
    "    print(f\"  Validating {provider_id.capitalize()} key with model '{test_model}'...\")\n",
    "\n",
    "    try:\n",
    "        validation_result = await llm_service.validate_api_key(\n",
    "            provider=provider_id, api_key=api_key, test_model=test_model\n",
    "        )\n",
    "        \n",
    "        if validation_result.get(\"valid\"):\n",
    "            result[\"status\"] = \"SUCCESS\"\n",
    "            result[\"message\"] = f\"Validated using model '{validation_result.get('response_model')}'.\"\n",
    "        else:\n",
    "            result[\"status\"] = \"FAILURE\"\n",
    "            result[\"message\"] = f\"Validation failed: {validation_result.get('error', 'Unknown error')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        result[\"status\"] = \"ERROR\"\n",
    "        result[\"message\"] = f\"An unexpected error occurred: {e}\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "async def run_validation_tests(llm_service):\n",
    "    \"\"\"\n",
    "    Main function to orchestrate all API key validation tests.\n",
    "    \"\"\"\n",
    "    if not llm_service:\n",
    "        print(\"LLMService not initialized. Cannot run API key validation.\")\n",
    "        return\n",
    "\n",
    "    print(\"--- Running LLM API Key Validation Tests ---\")\n",
    "    \n",
    "    # dotenv_values() loads from the current working directory.\n",
    "    # Ensure you run the notebook from the `backend/` directory.\n",
    "    env_values = dotenv_values()\n",
    "    all_providers = get_all_llm_providers()\n",
    "    \n",
    "    test_results = []\n",
    "    for provider in all_providers:\n",
    "        test_result = await test_provider_key(provider.provider_id, llm_service, env_values)\n",
    "        test_results.append(test_result)\n",
    "        \n",
    "        status_icon = {\n",
    "            \"SUCCESS\": \"‚úÖ\",\n",
    "            \"FAILURE\": \"‚ùå\",\n",
    "            \"ERROR\": \"‚ùå\",\n",
    "            \"SKIPPED\": \"‚è≠Ô∏è\",\n",
    "        }.get(test_result[\"status\"], \"‚ùì\")\n",
    "\n",
    "        print(f\"{status_icon} {provider.display_name}: {test_result['status']}\")\n",
    "        if test_result[\"status\"] != \"SUCCESS\":\n",
    "            print(f\"   -> {test_result['message']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"--- Test Summary ---\")\n",
    "\n",
    "    failures = [r for r in test_results if r[\"status\"] in [\"FAILURE\", \"ERROR\"]]\n",
    "    \n",
    "    if not failures:\n",
    "        print(\"\\n‚úÖ All configured LLM API key validation tests passed successfully.\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Found {len(failures)} validation failure(s):\")\n",
    "        for f in failures:\n",
    "            print(f\"  - Provider: {f['provider'].capitalize()} ({f['status']})\")\n",
    "            print(f\"    Details: {f['message']}\")\n",
    "        # Optionally, re-raise an exception if running in an automated context\n",
    "        # raise Exception(\"One or more API key validation tests failed.\")\n",
    "\n",
    "# To run the tests, execute this in your cell:\n",
    "await run_validation_tests(llm_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Chat Completion Test\n",
    "\n",
    "Test the `chat_completion` method. For this to work, you would typically need to store the user's API key in the database first, as `LLMService.chat_completion` fetches it from there.\n",
    "\n",
    "Since we don't have user authentication and API key storage endpoints set up yet, this example will be more conceptual or require manual key insertion for testing if `SKIP_DATABASE` is false and you're not mocking.\n",
    "\n",
    "**To make this work with a real key when `SKIP_DATABASE=False`:**\n",
    "1.  Manually insert a record into your `user_api_keys` table using a database client (e.g., `psql`).\n",
    "2.  Ensure you use the correct `user_id`, `provider`, and an **encrypted** `api_key` (you can use `src.utils.encryption.encrypt_api_key` in a separate notebook cell to get the encrypted value).\n",
    "\n",
    "**Example (for manual DB insertion, encrypted value needed):**\n",
    "```sql\n",
    "INSERT INTO user_api_keys (user_id, provider, encrypted_api_key, validation_status) \n",
    "VALUES ('<YOUR_UUID_HERE>', 'openai', '<ENCRYPTED_KEY_HERE>', 'valid');\n",
    "```\n",
    "\n",
    "Let's simulate a call assuming a user ID exists and their key is in the DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`SKIP_DATABASE` is true. This test requires a database connection.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Chat Completion Test\n",
    "import textwrap\n",
    "from uuid import uuid4, UUID\n",
    "from datetime import datetime\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Import core application components\n",
    "from src.core.encryption import encrypt_api_key\n",
    "from src.database.models import User\n",
    "from src.database.repositories.user import UserRepository\n",
    "from src.services.llm.llm_service import LLMMessage\n",
    "from src.core.llm.catalog import get_default_test_model_name_for_provider\n",
    "\n",
    "# --- Test Configuration ---\n",
    "# Add the 'provider_id' of each provider you want to test here.\n",
    "# The script will find the required API keys from your .env file.\n",
    "PROVIDERS_TO_TEST = [\"google\"] # e.g., [\"openai\", \"anthropic\", \"google\"]\n",
    "\n",
    "\n",
    "async def setup_test_user_and_key(get_db_session, user_id: UUID, provider_id: str, api_key: str):\n",
    "    \"\"\"Ensures a test user exists and stores their encrypted API key.\"\"\"\n",
    "    print(f\"      -> Setting up test user and API key for {provider_id} in DB...\")\n",
    "    encrypted_key = encrypt_api_key(api_key)\n",
    "    \n",
    "    async with anext(get_db_session()) as session:\n",
    "        # 1. Ensure user exists\n",
    "        user = await session.get(User, user_id)\n",
    "        if not user:\n",
    "            print(f\"      -> User not found. Creating test user: {user_id}\")\n",
    "            user = User(id=user_id, email=f\"test_user_{user_id.hex[:8]}@shuscribe.com\")\n",
    "            session.add(user)\n",
    "            await session.commit()\n",
    "            await session.refresh(user)\n",
    "        \n",
    "        # 2. Store/update key using the repository\n",
    "        repo = UserRepository(session)\n",
    "        await repo.store_api_key(\n",
    "            user_id=user_id,\n",
    "            provider=provider_id,\n",
    "            encrypted_key=encrypted_key,\n",
    "            validation_status=\"valid\", # Assume valid from previous test\n",
    "            last_validated_at=datetime.now()\n",
    "        )\n",
    "    print(\"      -> Setup complete.\")\n",
    "\n",
    "\n",
    "async def run_single_chat_test(llm_service, get_db_session, provider_id: str, test_user_id: UUID, env_values: dict):\n",
    "    \"\"\"Runs the full chat completion test for one provider.\"\"\"\n",
    "    result = {\"provider\": provider_id, \"status\": \"SKIPPED\", \"message\": \"\"}\n",
    "    \n",
    "    # 1. Check for required API key and model in catalog/environment\n",
    "    api_key = env_values.get(f\"{provider_id.upper()}_API_KEY\")\n",
    "    model = get_default_test_model_name_for_provider(provider_id)\n",
    "\n",
    "    if not api_key:\n",
    "        result[\"message\"] = f\"API key ({provider_id.upper()}_API_KEY) not found in .env\"\n",
    "        return result\n",
    "    if not model:\n",
    "        result[\"message\"] = \"Default test model not found in catalog\"\n",
    "        return result\n",
    "        \n",
    "    print(f\"\\n--- Testing Chat Completion for: {provider_id.capitalize()} ---\")\n",
    "    \n",
    "    try:\n",
    "        # 2. Setup user and key in the database\n",
    "        await setup_test_user_and_key(get_db_session, test_user_id, provider_id, api_key)\n",
    "\n",
    "        # 3. Perform the chat completion call\n",
    "        print(f\"      -> Calling chat_completion with model '{model}'...\")\n",
    "        messages = [\n",
    "            LLMMessage(role=\"system\", content=\"You are a helpful assistant.\"),\n",
    "            LLMMessage(role=\"user\", content=\"In one sentence, what is the most famous landmark in Paris?\"),\n",
    "        ]\n",
    "        \n",
    "        chat_response = await llm_service.chat_completion(\n",
    "            user_id=test_user_id, provider=provider_id, model=model, messages=messages\n",
    "        )\n",
    "        \n",
    "        # 4. Validate the response\n",
    "        assert chat_response.content, \"Response content is empty\"\n",
    "        assert \"Eiffel Tower\" in chat_response.content, \"Response did not contain 'Eiffel Tower'\"\n",
    "        \n",
    "        result[\"status\"] = \"SUCCESS\"\n",
    "        result[\"message\"] = f\"Received valid response from model '{chat_response.model}'.\"\n",
    "        result[\"response_content\"] = chat_response.content\n",
    "\n",
    "    except AssertionError as ae:\n",
    "        result[\"status\"] = \"FAILURE\"\n",
    "        result[\"message\"] = f\"Assertion failed: {ae}\"\n",
    "    except Exception as e:\n",
    "        result[\"status\"] = \"ERROR\"\n",
    "        result[\"message\"] = f\"An unexpected error occurred: {e.__class__.__name__}: {e}\"\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "async def run_chat_completion_tests(llm_service, user_repo, get_db_session):\n",
    "    \"\"\"Main function to orchestrate all chat completion tests.\"\"\"\n",
    "    \n",
    "    # Pre-flight checks\n",
    "    if not all([llm_service, user_repo, get_db_session]):\n",
    "        print(\"A required service (LLMService, UserRepository, or get_db_session) is not initialized.\")\n",
    "        return\n",
    "    if settings.SKIP_DATABASE:\n",
    "        print(\"`SKIP_DATABASE` is true. This test requires a database connection.\")\n",
    "        return\n",
    "\n",
    "    print(\"--- Running Chat Completion Tests ---\")\n",
    "    \n",
    "    env_values = dotenv_values()\n",
    "    test_user_id = UUID(env_values.get(\"NOTEBOOK_TEST_USER_ID\", str(uuid4())))\n",
    "    print(f\"Using Test User ID: {test_user_id}\\n\")\n",
    "    \n",
    "    results = []\n",
    "    for provider_id in PROVIDERS_TO_TEST:\n",
    "        test_result = await run_single_chat_test(llm_service, get_db_session, provider_id, test_user_id, env_values)\n",
    "        results.append(test_result)\n",
    "        \n",
    "        status_icon = {\"SUCCESS\": \"‚úÖ\", \"FAILURE\": \"‚ùå\", \"ERROR\": \"‚ùå\", \"SKIPPED\": \"‚è≠Ô∏è\"}.get(test_result[\"status\"], \"‚ùì\")\n",
    "        print(f\"{status_icon} Result for {provider_id.capitalize()}: {test_result['status']}\")\n",
    "        \n",
    "        # Print details for non-successful tests\n",
    "        if test_result['status'] != 'SUCCESS':\n",
    "             print(f\"   -> {test_result['message']}\")\n",
    "        else:\n",
    "            snippet = textwrap.shorten(test_result.get('response_content', ''), width=70, placeholder=\"...\")\n",
    "            print(f\"   -> Response: \\\"{snippet}\\\"\")\n",
    "            \n",
    "    # Final Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"--- Chat Completion Test Summary ---\")\n",
    "    failures = [r for r in results if r['status'] in ['FAILURE', 'ERROR']]\n",
    "    \n",
    "    if not failures:\n",
    "        print(\"\\n‚úÖ All configured chat completion tests passed successfully!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Found {len(failures)} failure(s):\")\n",
    "        for f in failures:\n",
    "            print(f\"  - Provider: {f['provider'].capitalize()} ({f['status']})\")\n",
    "            print(f\"    Details: {f['message']}\")\n",
    "\n",
    "# To run the tests, execute this in your cell:\n",
    "await run_chat_completion_tests(llm_service, user_repo, get_db_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Advanced Pipeline Component Testing\n",
    "\n",
    "You can now import and test other parts of the LLM pipeline, such as specific agents (e.g., `wikigen_orchestrator.py`, `article_writer_agent.py`) directly.\n",
    "\n",
    "```python\n",
    "from src.agents.wikigen.wikigen_orchestrator import WikiGenOrchestrator\n",
    "\n",
    "if llm_service:\n",
    "    orchestrator = WikiGenOrchestrator(llm_service=llm_service)\n",
    "    await orchestrator.generate_wiki(\n",
    "        story_title=\"Pokemon: Ambertwo\",\n",
    "        story_content=\"Pokemon fan gets isekai'd to the Pokemon world as a little girl. Join Dr. Fuji's apparently successful clone, as she explores this mishmash of Pokemon media and other creative liberties and grittier world.\",\n",
    "        output_dir=Path(\"tests/resources/pokemon_amber/story\"),\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=\"openai\",\n",
    "        model=\"gpt-4o\"\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Story Metadata ---\n",
      "{\n",
      "  \"title\": \"Pokemon: Ambertwo\",\n",
      "  \"author\": \"ChronicImmortality\",\n",
      "  \"synopsis\": \"Pokemon fan gets isekai'd to the Pokemon world as a little girl.\\n    Join Dr. Fuji's apparently successful clone, as she explores this mishmash of Pokemon media and other creative liberties and grittier world.\",\n",
      "  \"status\": \"In Progress\",\n",
      "  \"date_created\": \"2025-06-26\",\n",
      "  \"last_updated\": \"2025-06-26\",\n",
      "  \"copyright\": \"\\u00a9 2025 ChronicImmortality. All rights reserved.\",\n",
      "  \"genres\": [\n",
      "    \"Drama\",\n",
      "    \"Action\",\n",
      "    \"Adventure\",\n",
      "    \"Fantasy\"\n",
      "  ],\n",
      "  \"tags\": [\n",
      "    \"Reincarnation\",\n",
      "    \"Portal Fantasy/Isekai\",\n",
      "    \"Fan Fiction\",\n",
      "    \"Female Lead\",\n",
      "    \"Genetically Engineered\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "--- Chapters List ---\n",
      "  - Ref: 1.xml, Title: [Chapter 1] Truck-kun Strikes Again\n",
      "  - Ref: 2.xml, Title: [Chapter 2] All Aboard!\n",
      "  - Ref: 3.xml, Title: [Chapter 3] Into the World of (Pocket) Monsters\n",
      "  - Ref: 4.xml, Title: [Chapter 4] Achievement Unlocked! First Battle!\n",
      "  - Ref: 5.xml, Title: [Chapter 5] A Perfectly Normal Gym Session\n",
      "  - Ref: 6.xml, Title: [Chapter 6] Scientist Fuji\n",
      "  - Ref: 7.xml, Title: [Chapter 7] Side Quests Galore\n",
      "  - Ref: 8.xml, Title: [Chapter 8] Start of an Unpaid Side Quest\n",
      "  - Ref: 9.xml, Title: [Chapter 9] Side Quest: Trade Secrets\n",
      "  - Ref: 10.xml, Title: [Chapter 10] Side Quest: Complete!\n",
      "  - Ref: 11.xml, Title: [Chapter 11] Pallet Town\n",
      "  - Ref: 12.xml, Title: [Chapter 12] A Very Reasonable Man\n",
      "  - Ref: 13.xml, Title: [Chapter 13] Sweet Home\n",
      "  - Ref: 14.xml, Title: [Chapter 14] Flowers for Delia\n",
      "  - Ref: 15.xml, Title: [Chapter 15] Magmar v Electabuzz\n",
      "  - Ref: 16.xml, Title: [Chapter 16] Dr. Fuji v Professor Oak\n",
      "  - Ref: 17.xml, Title: [Chapter 17] The Eye of the Storm\n",
      "\n",
      "--- Loading First Chapter (1.xml) ---\n",
      "Chapter content (snippet):\n",
      "[Chapter 1] Truck-kun Strikes Again\n",
      "'Fuck,' I thought, hunched over my phone in the fading afternoon light. My fingers hovered over the screen as if I could somehow intimidate the numbers into change.\n",
      "My Gyarados‚Äîlevel 40, carefully trained, survivor of multiple gym battles and approximately eight thousand random Pidgey and Mankey encounters‚Äîwas down to a sliver of health. Across the battlefield, a level 37 Vulpix stared back with pixels that somehow managed to look smug. It had probably practic...\n"
     ]
    }
   ],
   "source": [
    "# New Cell or modified existing cell for testing StoryLoader\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from src.utils.story_loader import StoryLoader # For pretty printing dictionaries\n",
    "\n",
    "try:\n",
    "    # Ensure this path is correct relative to your notebook's CWD\n",
    "    # The notebook's CWD is backend/notebooks, so ../ goes up to backend/\n",
    "    story_directory_path = Path(\"../tests/resources/pokemon_amber/story\")\n",
    "    story_loader = StoryLoader(story_directory_path)\n",
    "\n",
    "    print(\"--- Story Metadata ---\")\n",
    "    metadata = story_loader.get_metadata()\n",
    "    if metadata:\n",
    "        print(json.dumps(metadata, indent=2))\n",
    "    else:\n",
    "        print(\"Metadata not loaded.\")\n",
    "\n",
    "    print(\"\\n--- Chapters List ---\")\n",
    "    chapters_list = story_loader.get_chapters_list()\n",
    "    for chapter in chapters_list:\n",
    "        print(f\"  - Ref: {chapter['ref']}, Title: {chapter['title']}\")\n",
    "\n",
    "    # Example: Load a specific chapter\n",
    "    if chapters_list:\n",
    "        first_chapter_ref = chapters_list[0][\"ref\"]\n",
    "        print(f\"\\n--- Loading First Chapter ({first_chapter_ref}) ---\")\n",
    "        first_chapter_content = story_loader.load_chapter(first_chapter_ref, True)\n",
    "        # Print only the first 500 characters to avoid overwhelming output\n",
    "        print(f\"Chapter content (snippet):\\n{first_chapter_content[:500]}...\")\n",
    "    else:\n",
    "        print(\"\\nNo chapters found to load.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
