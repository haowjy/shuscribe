{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# WikiGen Agent Streaming Workflow\n",
    "\n",
    "This notebook demonstrates **efficient streaming** with WikiGen agents using **single LLM calls** that provide both real-time feedback and structured results.\n",
    "\n",
    "## 🎯 Key Principle: One Call, Two Benefits\n",
    "\n",
    "Instead of making wasteful duplicate API calls, we:\n",
    "1. **Stream** for real-time user feedback  \n",
    "2. **Accumulate** content during streaming\n",
    "3. **Parse** accumulated result into structured data\n",
    "\n",
    "**💰 Result**: 50% cost savings + better UX!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "✅ Setup complete - ready for efficient streaming tests!\n"
     ]
    }
   ],
   "source": [
    "# Setup and Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "from uuid import uuid4\n",
    "from typing import cast\n",
    "\n",
    "# Set environment for testing\n",
    "os.environ[\"SKIP_DATABASE\"] = \"true\"\n",
    "os.environ[\"PORTKEY_BASE_URL\"] = \"http://localhost:8787/v1\"\n",
    "\n",
    "# Add src to path\n",
    "notebook_dir = Path.cwd()\n",
    "if (notebook_dir / 'src').is_dir():\n",
    "    sys.path.insert(0, str(notebook_dir / 'src'))\n",
    "elif (notebook_dir.parent / 'src').is_dir():\n",
    "    sys.path.insert(0, str(notebook_dir.parent / 'src'))\n",
    "\n",
    "# Import services and agents\n",
    "from src.services.llm.llm_service import LLMService\n",
    "from src.database.repositories import get_user_repository, get_story_repository\n",
    "from src.agents.wikigen.arc_splitter import ArcSplitterAgent\n",
    "from src.schemas.wikigen.arc import ArcAnalysisResult\n",
    "from src.core.story_loading import StoryLoaderFactory\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "print(\"✅ Setup complete - ready for efficient streaming tests!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔑 Available providers: ['openai', 'google', 'anthropic']\n",
      "📖 Loaded: Pokemon: Ambertwo\n",
      "📊 Chapters: 17, Characters: 273,713\n",
      "🎯 Ready for streaming tests!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Services and Load Test Data\n",
    "\n",
    "# Initialize repositories and LLM service\n",
    "user_repo = get_user_repository()\n",
    "story_repo = get_story_repository()\n",
    "llm_service = LLMService(user_repository=user_repo)\n",
    "\n",
    "# Load API keys from .env\n",
    "env_values = dotenv_values()\n",
    "AVAILABLE_PROVIDERS = {}\n",
    "for provider in LLMService.get_all_llm_providers():\n",
    "    provider_id = provider.provider_id\n",
    "    api_key = env_values.get(f\"{provider_id.upper()}_API_KEY\")\n",
    "    if api_key:\n",
    "        AVAILABLE_PROVIDERS[provider_id] = {\n",
    "            'name': provider.display_name,\n",
    "            'api_key': api_key\n",
    "        }\n",
    "\n",
    "print(f\"🔑 Available providers: {list(AVAILABLE_PROVIDERS.keys())}\")\n",
    "\n",
    "# Load test story\n",
    "story_directory_path = Path(\"../tests/resources/pokemon_amber/story\")\n",
    "input_story = StoryLoaderFactory.load_story(story_directory_path)\n",
    "\n",
    "# Store in repository\n",
    "fake_owner_id = uuid4()\n",
    "stored_story = await story_repo.store_input_story(input_story, fake_owner_id)\n",
    "\n",
    "# Prepare story content\n",
    "story_content = \"\\\\n\\\\n\".join([\n",
    "    f\"# {chapter.title}\\\\n{chapter.content}\" \n",
    "    for chapter in input_story.chapters\n",
    "])\n",
    "\n",
    "print(f\"📖 Loaded: {input_story.metadata.title}\")\n",
    "print(f\"📊 Chapters: {len(input_story.chapters)}, Characters: {len(story_content):,}\")\n",
    "print(f\"🎯 Ready for streaming tests!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🔄 Efficient Streaming: ArcSplitter Agent\n",
    "\n",
    "**Single LLM call with real-time streaming + structured output**\n",
    "\n",
    "This demonstrates the optimal pattern:\n",
    "- ⚡ Real-time user feedback during processing\n",
    "- 📊 Accumulate content as it streams  \n",
    "- 🎯 Parse final result into structured data\n",
    "- 💰 **Only one API call** - no waste!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Testing with: openai / gpt-4.1-nano\n",
      "📖 Story: Pokemon: Ambertwo (17 chapters)\n",
      "\\n⚡ Starting efficient streaming analysis...\n",
      "📡 Live stream output:\n",
      "--------------------------------------------------\n",
      "2025-06-29 01:41:16,933 - src.services.llm.llm_service - INFO - Using direct API key for provider=openai, model=gpt-4.1-nano\n",
      "2025-06-29 01:41:16,962 - src.services.llm.llm_service - INFO - Model gpt-4.1-nano supports structured output - using response_format parameter\n",
      "2025-06-29 01:41:16,962 - src.services.llm.llm_service - INFO - Using standard schema for provider: openai\n",
      "2025-06-29 01:41:16,962 - src.services.llm.llm_service - INFO - Making LLM request: provider=openai, model=gpt-4.1-nano, gateway=http://localhost:8787/v1, streaming=True\n",
      "{\"arcs\":[{\"id\":1,\"title\":\"Introduction and Sudden Transition to a New World\",\"start_chapter\":1,\"end_chapter\":2,\"summary\":\"The story begins with the protagonist immersed in a Pokémon battle on their phone, which is abruptly interrupted by a mysterious accident involving Mewtwo and Dr. Fuji. The protagonist is transported into a new, real-world environment, experiencing the shock of their body being that of Dr. Fuji's daughter, and witnessing the chaos of a Pokémon battle in a laboratory. This arc establishes the protagonist's initial circumstances, the transition from their old life to the new world, and the immediate danger and confusion they face.\",\"key_events\":\"Protagonist's last battle on phone; notification about Shadow Mewtwo raid; sudden transportation into Dr. Fuji's lab; encounter with Mewtwo and Dr. Fuji; chaos of the lab breach; realization of being in a new, real-world environment; initial shock and confusion.\"},{\"id\":2,\"title\":\"Adjustment to the New Reality and Early Exploration\",\"start_chapter\":3,\"end_chapter\":4,\"summary\":\"The protagonist begins to acclimate to their new body and environment, including dressing and interacting with Ditto. They explore the laboratory ruins, witness Pokémon battles in the city, and start to understand the world they are in—an Earth where Pokémon are integrated into daily life. The protagonist also takes their first steps toward becoming a Pokémon trainer, observing battles and practicing with Ditto, setting the foundation for their future journey.\",\"key_events\":\"Fitting into Dr. Fuji's daughter’s body; transforming Ditto; observing Pokémon battles on TV; exploring Celadon City; planning to visit the gym; first real-world Pokémon encounters.\"},{\"id\":3,\"title\":\"First Pokémon Battle and Beginning of Training\",\"start_chapter\":5,\"end_chapter\":6,\"summary\":\"The protagonist visits Celadon Gym and witnesses Pokémon battles in the city park, gaining insight into real Pokémon combat. They then engage in their first battle with a young trainer, testing Ditto’s abilities and starting their journey as a trainer. This arc marks the transition from observer to active participant in the Pokémon world, emphasizing the protagonist’s determination and adaptation.\",\"key_events\":\"Visiting Celadon Gym; observing battles; engaging in their first battle with Joey’s Rattata; testing Ditto’s capabilities; solidifying the desire to train and grow stronger.\"},{\"id\":4,\"title\":\"Training, Strategy, and Building Confidence\",\"start_chapter\":7,\"end_chapter\":9,\"summary\":\"The protagonist dedicates time to training Ditto, experimenting with transformations, and learning how to utilize their Pokémon effectively. They practice transforming into various Pokémon, study battle tactics, and build confidence in their abilities. This arc focuses on character growth, developing skills, and preparing for future challenges.\",\"key_events\":\"Practicing transformations; training Ditto with different Pokémon; gaining confidence; understanding the importance of strategy; preparing for upcoming battles.\"},{\"id\":5,\"title\":\"Encounter with a Challenger and the First Tournament\",\"start_chapter\":10,\"end_chapter\":12,\"summary\":\"The protagonist faces a new challenger, Joey, in an impromptu battle, testing their skills under pressure. They participate in a local Pokémon tournament, confronting stronger opponents and applying their training. This arc represents a significant step in their journey, showcasing growth, resilience, and the challenges of real competition.\",\"key_events\":\"Joey’s challenge; tournament participation; applying training in real battles; overcoming initial setbacks; gaining experience.\"},{\"id\":6,\"title\":\"Deeper Mysteries and the Threat of Team Rocket\",\"start_chapter\":13,\"end_chapter\":15,\"summary\":\"The story delves into the larger conspiracy involving Team Rocket and the secret experiments behind Mewtwo’s creation. The protagonist uncovers hints of their own importance in the ongoing conflict and the potential dangers of their unique situation. This arc introduces a new antagonist force and raises the stakes for the protagonist’s future.\",\"key_events\":\"Discovery of Team Rocket’s involvement; uncovering the secret behind Mewtwo; realizing their own significance; facing new threats.\"},{\"id\":7,\"title\":\"Climax, Resolution, and New Beginnings\",\"start_chapter\":16,\"end_chapter\":17,\"summary\":\"The protagonist confronts the climax of the story, dealing with the threats posed by Team Rocket and the chaos caused by Mewtwo. They make critical decisions that determine their future and the fate of the Pokémon world. The story concludes with a sense of hope and new purpose, setting the stage for further adventures.\",\"key_events\":\"Final confrontation with Team Rocket; resolving the chaos caused by Mewtwo; character growth and acceptance; looking forward to future adventures.\"}],\"story_prediction\":\"The story is likely to continue exploring the protagonist’s growth as a trainer, deeper involvement in the Pokémon world’s conflicts, and possibly uncovering more about their origin and purpose. Future plot directions may include more encounters with legendary Pokémon, alliances with other trainers, and the resolution of the overarching conspiracy involving Team Rocket.\",\"growth_assessment\":\"The story is expanding from initial shock and discovery to active participation and strategic development. The protagonist’s understanding of the Pokémon world deepens, and their skills improve, setting the stage for more complex challenges and character development.\",\"consolidation_reasoning\":\"The story’s length and complexity suggest that these arcs are natural divisions that allow for coherent storytelling, character growth, and plot advancement. Each arc builds upon the previous, ensuring a logical progression while leaving room for future expansion.\",\"arc_strategy\":\"The division strategy was to start with the protagonist’s sudden arrival and initial adaptation, then move through their growth as a trainer, encounters with opponents, and the uncovering of larger threats. Each arc ends at a natural story beat—such as a battle, discovery, or decision—making them suitable for detailed wiki articles.\"}\\n--------------------------------------------------\n",
      "✅ Streaming completed with single LLM call!\n",
      "📊 Chunks received: 1194\n",
      "📝 Content length: 6181 chars\n",
      "\\n🔍 Parsing streamed content...\n",
      "✅ Successfully parsed streaming result!\n",
      "⚠️  Parse error: 'ArcAnalysisResult' object has no attribute 'story_stats'\n",
      "📄 Raw content: {\"arcs\":[{\"id\":1,\"title\":\"Introduction and Sudden Transition to a New World\",\"start_chapter\":1,\"end_chapter\":2,\"summary\":\"The story begins with the protagonist immersed in a Pokémon battle on their ph...\n",
      "💡 Note: Some models may not return valid JSON in streaming mode\n"
     ]
    }
   ],
   "source": [
    "# Efficient Streaming Test - Single LLM Call\n",
    "\n",
    "if not AVAILABLE_PROVIDERS:\n",
    "    print(\"❌ No API keys available. Please add API keys to your .env file.\")\n",
    "else:\n",
    "    # Use first available provider\n",
    "    provider = list(AVAILABLE_PROVIDERS.keys())[0]\n",
    "    api_key = AVAILABLE_PROVIDERS[provider]['api_key']\n",
    "    model = LLMService.get_default_test_model_name_for_provider(provider)\n",
    "    \n",
    "    print(f\"🔧 Testing with: {provider} / {model}\")\n",
    "    print(f\"📖 Story: {input_story.metadata.title} ({len(input_story.chapters)} chapters)\")\n",
    "    \n",
    "    # Initialize agent\n",
    "    arc_splitter = ArcSplitterAgent(\n",
    "        llm_service=llm_service,\n",
    "        default_provider=provider,\n",
    "        default_model=model\n",
    "    )\n",
    "    \n",
    "    print(f\"\\\\n⚡ Starting efficient streaming analysis...\")\n",
    "    print(\"📡 Live stream output:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 🎯 EFFICIENT PATTERN: Single call with streaming + accumulation\n",
    "    accumulated_content = \"\"\n",
    "    chunk_count = 0\n",
    "    \n",
    "    async for chunk in arc_splitter.analyze_story_streaming(\n",
    "        story_title=input_story.metadata.title,\n",
    "        story_content=story_content[:50000],  # Truncate for demo\n",
    "        total_chapters=len(input_story.chapters),\n",
    "        user_id=fake_owner_id,\n",
    "        api_key=api_key,\n",
    "        genre=\"Isekai Fantasy\"\n",
    "    ):\n",
    "        chunk_count += 1\n",
    "        content = chunk.content\n",
    "        accumulated_content += content  # 📊 Accumulate for parsing\n",
    "        \n",
    "        # ⚡ Real-time feedback to user\n",
    "        if content:\n",
    "            print(content, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\\\n\" + \"-\" * 50)\n",
    "    print(f\"✅ Streaming completed with single LLM call!\")\n",
    "    print(f\"📊 Chunks received: {chunk_count}\")\n",
    "    print(f\"📝 Content length: {len(accumulated_content)} chars\")\n",
    "    \n",
    "    # 🎯 Parse accumulated result into structured format\n",
    "    print(f\"\\\\n🔍 Parsing streamed content...\")\n",
    "    try:\n",
    "        # Parse the accumulated JSON response\n",
    "        final_result = ArcAnalysisResult.model_validate_json(accumulated_content)\n",
    "        \n",
    "        print(f\"✅ Successfully parsed streaming result!\")\n",
    "        print(f\"📋 Recommended arcs: {final_result.story_stats.recommended_arcs}\")\n",
    "        print(f\"📖 Generated arcs: {len(final_result.arcs)}\")\n",
    "        \n",
    "        # Show first arc as example\n",
    "        if final_result.arcs:\n",
    "            first_arc = final_result.arcs[0]\n",
    "            print(f\"\\\\n🏛️  Arc 1: {first_arc.title}\")\n",
    "            print(f\"   📖 Chapters: {first_arc.start_chapter}-{first_arc.end_chapter}\")\n",
    "            print(f\"   📝 Summary: {first_arc.summary[:100]}...\")\n",
    "            \n",
    "        print(f\"\\\\n🎯 SUCCESS: Real-time streaming + structured output with single API call!\")\n",
    "        \n",
    "    except Exception as parse_error:\n",
    "        print(f\"⚠️  Parse error: {parse_error}\")\n",
    "        print(f\"📄 Raw content: {accumulated_content[:200]}...\")\n",
    "        print(\"💡 Note: Some models may not return valid JSON in streaming mode\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 📊 Pattern Comparison\n",
    "\n",
    "### ✅ EFFICIENT: Single Call with Accumulation\n",
    "```python\n",
    "accumulated_content = \"\"\n",
    "async for chunk in agent.analyze_story_streaming(...):\n",
    "    print(chunk.content, end=\"\", flush=True)    # Real-time feedback\n",
    "    accumulated_content += chunk.content        # Accumulate content\n",
    "\n",
    "# Parse accumulated result\n",
    "result = ArcAnalysisResult.model_validate_json(accumulated_content)\n",
    "```\n",
    "\n",
    "### ❌ WASTEFUL: Double API Calls  \n",
    "```python\n",
    "# Call 1: Streaming (costs money)\n",
    "async for chunk in agent.analyze_story_streaming(...):\n",
    "    print(chunk.content, end=\"\")\n",
    "    \n",
    "# Call 2: Non-streaming (costs money again!)\n",
    "result = await agent.analyze_story(...)  # DUPLICATE WORK!\n",
    "```\n",
    "\n",
    "### 🎯 Benefits of Efficient Pattern\n",
    "- 💰 **50% cost reduction** - One call instead of two\n",
    "- ⚡ **Better performance** - No duplicate processing  \n",
    "- 🔄 **Same UX** - Real-time streaming feedback\n",
    "- 📊 **Same output** - Structured data for downstream use\n",
    "- 🌱 **Environmentally friendly** - Less compute waste\n",
    "\n",
    "**Conclusion**: Always use streaming with accumulation for the best balance of cost, performance, and user experience!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiGen Agent Workflow Testing\n",
    "\n",
    "This notebook provides an environment to test the WikiGen agent-based story processing workflow using the new **BaseAgent architecture**. Each agent can be tested individually with different LLM models to demonstrate the flexibility and modularity of the system.\n",
    "\n",
    "## 🏗️ BaseAgent Architecture\n",
    "\n",
    "All WikiGen agents now inherit from `BaseAgent`, providing:\n",
    "- **Default Models**: Each agent has configurable default provider/model\n",
    "- **Override Flexibility**: Can override provider/model per call when needed  \n",
    "- **Centralized LLM Logic**: Common error handling and validation\n",
    "- **Clean API**: Simplified method signatures with optional parameters\n",
    "\n",
    "## 📋 WikiGen Agents\n",
    "\n",
    "1. **ArcSplitter Agent** - Analyzes story structure and determines arc boundaries\n",
    "2. **WikiPlanner Agent** - Plans wiki structure and article organization  \n",
    "3. **ArticleWriter Agent** - Generates actual wiki article content\n",
    "4. **GeneralSummarizer Agent** - Creates summaries of various content types\n",
    "5. **ChapterBacklinker Agent** - Creates bidirectional links between chapters and articles\n",
    "6. **WikiGenOrchestrator** - Coordinates the complete workflow\n",
    "\n",
    "Each agent demonstrates the BaseAgent pattern with different default models to show architectural flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ Setup\n",
    "\n",
    "Make sure the Portkey Gateway is running to use the LLM Service:\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  --name portkey-gateway \\\n",
    "  -p 8787:8787 \\\n",
    "  portkeyai/gateway:latest\n",
    "```\n",
    "\n",
    "The following cells will:\n",
    "- use the Portkey Gateway to test the LLM Service\n",
    "- initialize the LLM Service\n",
    "- import the WikiGen workflow agents\n",
    "- load a test story from the `tests/resources/pokemon_amber/story` directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "🚀 WikiGen Agent Workflow Testing Environment\n",
      "============================================================\n",
      "Current working directory: /home/jimnix/gitrepos/shuscribe/backend/notebooks\n",
      "Database mode: IN-MEMORY\n",
      "Portkey Gateway: http://localhost:8787/v1\n",
      "Autoreload enabled. Changes to .py files in src/ will be reloaded.\n",
      "\n",
      "💡 This notebook tests WikiGen agents with real LLM calls.\n",
      "   Each agent can use different models to demonstrate flexibility.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Configuration\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import logging\n",
    "from uuid import uuid4\n",
    "from typing import Dict, Any, List, cast\n",
    "\n",
    "# Set environment to skip database for testing\n",
    "os.environ[\"SKIP_DATABASE\"] = \"true\"\n",
    "os.environ[\"PORTKEY_BASE_URL\"] = \"http://localhost:8787/v1\"  # Default Portkey Gateway\n",
    "\n",
    "# Add the backend/src directory to sys.path\n",
    "notebook_dir = Path.cwd()\n",
    "if (notebook_dir / 'src').is_dir() and (notebook_dir / 'pyproject.toml').is_file():\n",
    "    # This means we're likely in the backend/ directory itself\n",
    "    sys.path.insert(0, str(notebook_dir / 'src'))\n",
    "elif (notebook_dir.parent / 'src').is_dir() and (notebook_dir.parent / 'pyproject.toml').is_file():\n",
    "    # This means we're likely in the backend/notebooks/ directory\n",
    "    sys.path.insert(0, str(notebook_dir.parent / 'src'))\n",
    "else:\n",
    "    print(\"Warning: Could not automatically add 'src/' to Python path.\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "# Reduce noise from third-party loggers\n",
    "logging.getLogger('httpx').setLevel(logging.WARNING)\n",
    "logging.getLogger('uvicorn.access').setLevel(logging.WARNING)\n",
    "\n",
    "print(\"🚀 WikiGen Agent Workflow Testing Environment\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Database mode: {'IN-MEMORY' if os.environ.get('SKIP_DATABASE') == 'true' else 'SUPABASE'}\")\n",
    "print(f\"Portkey Gateway: {os.environ.get('PORTKEY_BASE_URL', 'Not configured')}\")\n",
    "print(\"Autoreload enabled. Changes to .py files in src/ will be reloaded.\")\n",
    "print(\"\\n💡 This notebook tests WikiGen agents with real LLM calls.\")\n",
    "print(\"   Each agent can use different models to demonstrate flexibility.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modules imported successfully.\n",
      "\n",
      "--- Current Settings ---\n",
      "DEBUG: True\n",
      "ENVIRONMENT: development\n",
      "SKIP_DATABASE: True\n",
      "PORTKEY_BASE_URL: http://localhost:8787/v1\n",
      "DATABASE_MODE: In-Memory (Supabase skipped)\n",
      "------------------------\n",
      "\n",
      "🔧 Import Summary:\n",
      "✅ LLMService - Ready for testing\n",
      "✅ WikiGen Agents - All 5 agents + orchestrator imported\n",
      "✅ Story Loading - Test story will be loaded\n",
      "✅ Repository Factory - In-memory repositories for testing\n",
      "✅ Pydantic Models - Type-safe schemas\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Modules\n",
    "from src.config import settings\n",
    "from src.services.llm.llm_service import LLMService\n",
    "from src.database.repositories import get_user_repository, get_story_repository\n",
    "from src.schemas.llm.models import LLMMessage, LLMResponse\n",
    "from src.core.story_loading import StoryLoaderFactory\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# WikiGen agent imports\n",
    "from src.agents.wikigen import (\n",
    "    WikiGenOrchestrator,\n",
    "    ArcSplitterAgent,\n",
    "    WikiPlannerAgent,\n",
    "    ArticleWriterAgent,\n",
    "    GeneralSummarizerAgent,\n",
    "    ChapterBacklinkerAgent\n",
    ")\n",
    "\n",
    "print(\"✅ Modules imported successfully.\")\n",
    "\n",
    "# Display current settings\n",
    "print(\"\\n--- Current Settings ---\")\n",
    "print(f\"DEBUG: {settings.DEBUG}\")\n",
    "print(f\"ENVIRONMENT: {settings.ENVIRONMENT}\")\n",
    "print(f\"SKIP_DATABASE: {settings.SKIP_DATABASE}\")\n",
    "print(f\"PORTKEY_BASE_URL: {settings.PORTKEY_BASE_URL}\")\n",
    "print(\"DATABASE_MODE: In-Memory (Supabase skipped)\")\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"\\n🔧 Import Summary:\")\n",
    "print(\"✅ LLMService - Ready for testing\")\n",
    "print(\"✅ WikiGen Agents - All 5 agents + orchestrator imported\") \n",
    "print(\"✅ Story Loading - Test story will be loaded\")\n",
    "print(\"✅ Repository Factory - In-memory repositories for testing\")\n",
    "print(\"✅ Pydantic Models - Type-safe schemas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Initializing Services and Loading Test Story...\n",
      "============================================================\n",
      "✅ Services initialized successfully!\n",
      "📁 Repository types: InMemoryUserRepository, InMemoryStoryRepository\n",
      "\n",
      "🔑 Loading API Keys from .env...\n",
      "✅ OpenAI: API key found\n",
      "✅ Google: API key found\n",
      "✅ Anthropic: API key found\n",
      "\n",
      "📊 Available Providers: 3\n",
      "\n",
      "📖 Loading Test Story...\n",
      "✅ Loaded: Pokemon: Ambertwo\n",
      "   Author: ChronicImmortality\n",
      "   Chapters: 17\n",
      "   Genres: Drama, Action, Adventure, Fantasy\n",
      "   Stored with ID: 3a19f5df-e91d-4597-a021-636dbd623f3b\n",
      "\n",
      "📊 Test Data Summary:\n",
      "   Total characters: 273,664\n",
      "   First chapter: [Chapter 1] Truck-kun Strikes Again\n",
      "   Last chapter: [Chapter 17] The Eye of the Storm\n",
      "\n",
      "🎯 Ready for WikiGen agent testing with 3 LLM providers!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize Services and Load Test Story\n",
    "\n",
    "print(\"🚀 Initializing Services and Loading Test Story...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize repositories and LLM service\n",
    "user_repo = get_user_repository()\n",
    "story_repo = get_story_repository()\n",
    "llm_service = LLMService(user_repository=user_repo)\n",
    "\n",
    "print(\"✅ Services initialized successfully!\")\n",
    "print(f\"📁 Repository types: {type(user_repo).__name__}, {type(story_repo).__name__}\")\n",
    "\n",
    "# Load API keys from .env\n",
    "env_values = dotenv_values()\n",
    "print(\"\\n🔑 Loading API Keys from .env...\")\n",
    "\n",
    "# Check which providers have API keys available\n",
    "AVAILABLE_PROVIDERS: dict[str, dict[str, str]] = {}\n",
    "for provider in LLMService.get_all_llm_providers():\n",
    "    provider_id = provider.provider_id\n",
    "    api_key = env_values.get(f\"{provider_id.upper()}_API_KEY\")\n",
    "    if api_key:\n",
    "        AVAILABLE_PROVIDERS[provider_id] = {\n",
    "            'name': provider.display_name,\n",
    "            'api_key': api_key\n",
    "        }\n",
    "        print(f\"✅ {provider.display_name}: API key found\")\n",
    "    else:\n",
    "        print(f\"⏭️  {provider.display_name}: No API key found\")\n",
    "\n",
    "print(f\"\\n📊 Available Providers: {len(AVAILABLE_PROVIDERS)}\")\n",
    "\n",
    "# Load test story\n",
    "print(\"\\n📖 Loading Test Story...\")\n",
    "story_directory_path = Path(\"../tests/resources/pokemon_amber/story\")\n",
    "\n",
    "try:\n",
    "    input_story = StoryLoaderFactory.load_story(story_directory_path)\n",
    "    print(f\"✅ Loaded: {input_story.metadata.title}\")\n",
    "    print(f\"   Author: {input_story.metadata.author}\")\n",
    "    print(f\"   Chapters: {input_story.total_chapters}\")\n",
    "    print(f\"   Genres: {', '.join(input_story.metadata.genres)}\")\n",
    "    \n",
    "    # Store in repository for testing\n",
    "    fake_owner_id = uuid4()\n",
    "    stored_story = await story_repo.store_input_story(input_story, fake_owner_id)\n",
    "    print(f\"   Stored with ID: {stored_story.id}\")\n",
    "    \n",
    "    # Prepare story content for agent testing\n",
    "    story_content = \"\\n\\n\".join([\n",
    "        f\"# {chapter.title}\\n{chapter.content}\" \n",
    "        for chapter in input_story.chapters\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\n📊 Test Data Summary:\")\n",
    "    print(f\"   Total characters: {len(story_content):,}\")\n",
    "    print(f\"   First chapter: {input_story.chapters[0].title}\")\n",
    "    print(f\"   Last chapter: {input_story.chapters[-1].title}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading story: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\n🎯 Ready for WikiGen agent testing with {len(AVAILABLE_PROVIDERS)} LLM providers!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run individual agents\n",
    "\n",
    "## 📋 WikiGen Agents\n",
    "\n",
    "1. **ArcSplitter Agent** - Analyzes story structure and determines arc boundaries\n",
    "2. **WikiPlanner Agent** - Plans wiki structure and article organization  \n",
    "3. **ArticleWriter Agent** - Generates actual wiki article content\n",
    "4. **GeneralSummarizer Agent** - Creates summaries of various content types\n",
    "5. **ChapterBacklinker Agent** - Creates bidirectional links between chapters and articles\n",
    "6. **WikiGenOrchestrator** - Coordinates the complete workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArcSplitter Agent - Streaming Analysis\n",
    "\n",
    "**🔄 Single LLM Call with Real-time Streaming!**\n",
    "\n",
    "The ArcSplitter agent now supports **streaming analysis** that provides real-time feedback while accumulating the final structured result. This approach uses **only one LLM call** for both user experience and final parsing.\n",
    "\n",
    "- ⚡ **Real-time Feedback** - See analysis progress as it happens\n",
    "- 🚀 **Single LLM Call** - No wasteful duplicate API calls  \n",
    "- 📊 **Live Updates** - Stream response chunks as they're generated\n",
    "- 🎯 **Smart Accumulation** - Parse final accumulated result into structured data\n",
    "- 💰 **Cost Efficient** - One call gives you both streaming UX and structured output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Testing ArcSplitter Agent - STREAMING Analysis\n",
      "============================================================\n",
      "This demonstrates real-time streaming during story analysis.\n",
      "💡 You'll see the analysis progress in real-time as chunks arrive!\n",
      "🔧 Streaming with: google / gemini-2.0-flash-001\n",
      "📊 Story: Pokemon: Ambertwo (17 chapters)\n",
      "\\n⚡ Starting streaming analysis...\n",
      "📡 Live stream output:\n",
      "----------------------------------------\n",
      "2025-06-29 01:42:42,412 - src.services.llm.llm_service - INFO - Using direct API key for provider=google, model=gemini-2.0-flash-001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-29 01:42:42,441 - src.services.llm.llm_service - INFO - Model gemini-2.0-flash-001 supports structured output - using response_format parameter\n",
      "2025-06-29 01:42:42,442 - src.services.llm.llm_service - INFO - Using simplified schema for Google Gemini (removed validation constraints)\n",
      "2025-06-29 01:42:42,442 - src.services.llm.llm_service - INFO - Making LLM request: provider=google, model=gemini-2.0-flash-001, gateway=http://localhost:8787/v1, streaming=True\n",
      "2025-06-29 01:42:45,992 - portkey_ai._vendor.openai._base_client - INFO - Retrying request to /chat/completions in 0.461047 seconds\n",
      "❌ Streaming test failed: Error code: 503 - {'error': {'message': 'Invalid response received from google: [{\"error\":{\"code\":503,\"message\":\"The model is overloaded. Please try again later.\",\"status\":\"UNAVAILABLE\"}}]', 'type': None, 'param': None, 'code': None}, 'provider': 'google'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_159698/2464946418.py\", line 34, in <module>\n",
      "    async for chunk in arc_splitter_streaming.analyze_story_streaming(\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/src/agents/wikigen/arc_splitter.py\", line 198, in analyze_story_streaming\n",
      "    async for chunk in response_stream:\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/src/services/llm/llm_service.py\", line 302, in _stream_response_to_llm_response\n",
      "    else:\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages/portkey_ai/api_resources/apis/chat_complete.py\", line 323, in stream_create\n",
      "    async with self.openai_client.with_streaming_response.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages/portkey_ai/_vendor/openai/_response.py\", line 650, in __aenter__\n",
      "    self.__response = await self._api_request\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages/portkey_ai/_vendor/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages/portkey_ai/_vendor/openai/_base_client.py\", line 1765, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jimnix/gitrepos/shuscribe/backend/.venv/lib/python3.12/site-packages/portkey_ai/_vendor/openai/_base_client.py\", line 1572, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.InternalServerError: Error code: 503 - {'error': {'message': 'Invalid response received from google: [{\"error\":{\"code\":503,\"message\":\"The model is overloaded. Please try again later.\",\"status\":\"UNAVAILABLE\"}}]', 'type': None, 'param': None, 'code': None}, 'provider': 'google'}\n"
     ]
    }
   ],
   "source": [
    "# Cell: 4 Test ArcSplitter Agent - Streaming Version\n",
    "\n",
    "print(\"\\n🔄 Testing ArcSplitter Agent - STREAMING Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This demonstrates real-time streaming during story analysis.\")\n",
    "print(\"💡 You'll see the analysis progress in real-time as chunks arrive!\")\n",
    "\n",
    "if not AVAILABLE_PROVIDERS:\n",
    "    print(\"❌ No API keys available. Please add API keys to your .env file.\")\n",
    "else:\n",
    "    provider = \"openai\"  # Use Google for streaming demo    \n",
    "    api_key = AVAILABLE_PROVIDERS[provider]['api_key']\n",
    "    model = LLMService.get_default_test_model_name_for_provider(provider)\n",
    "    \n",
    "    print(f\"🔧 Streaming with: {provider} / {model}\")\n",
    "    print(f\"📊 Story: {input_story.metadata.title} ({len(input_story.chapters)} chapters)\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize the agent\n",
    "        arc_splitter_streaming = ArcSplitterAgent(\n",
    "            llm_service=llm_service,\n",
    "            default_provider=provider,\n",
    "            default_model=model\n",
    "        )\n",
    "        \n",
    "        print(f\"\\\\n⚡ Starting streaming analysis...\")\n",
    "        print(\"📡 Live stream output:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Stream the analysis in real-time and accumulate the response\n",
    "        chunk_count = 0\n",
    "        accumulated_content = \"\"\n",
    "        \n",
    "        async for chunk in arc_splitter_streaming.analyze_story_streaming(\n",
    "            story_title=input_story.metadata.title,\n",
    "            story_content=story_content,  # Truncate for faster demo\n",
    "            total_chapters=len(input_story.chapters),\n",
    "            user_id=fake_owner_id,\n",
    "            api_key=api_key,\n",
    "            genre=\"Isekai Fantasy\"\n",
    "        ):\n",
    "            chunk_count += 1\n",
    "            content = chunk.content\n",
    "            accumulated_content += content\n",
    "            \n",
    "            # Print streaming content in real-time\n",
    "            if content:\n",
    "                print(content, end=\"\", flush=True)\n",
    "        \n",
    "        print(\"\\\\n\" + \"-\" * 40)\n",
    "        print(f\"✅ Streaming completed with single LLM call!\")\n",
    "        print(f\"📊 Total chunks received: {chunk_count}\")\n",
    "        print(f\"📝 Total content length: {len(accumulated_content)} characters\")\n",
    "        \n",
    "        # Parse the accumulated streaming result into structured format\n",
    "        print(f\"\\\\n🎯 Parsing streamed content into structured result...\")\n",
    "        try:\n",
    "            from src.schemas.wikigen.arc import ArcAnalysisResult\n",
    "            \n",
    "            # Parse the accumulated JSON response from streaming\n",
    "            final_result = ArcAnalysisResult.model_validate_json(accumulated_content)\n",
    "            \n",
    "            print(f\"✅ Successfully parsed streaming result!\")\n",
    "            print(f\"📖 Number of arcs generated: {len(final_result.arcs)}\")\n",
    "            \n",
    "            # Show first arc as example\n",
    "            if final_result.arcs:\n",
    "                first_arc = final_result.arcs[0]\n",
    "                print(f\"\\\\n🏛️  First Arc: {first_arc.title}\")\n",
    "                print(f\"   📖 Chapters: {first_arc.start_chapter}-{first_arc.end_chapter}\")\n",
    "                print(f\"   📝 Summary: {first_arc.summary[:100]}...\")\n",
    "                \n",
    "        except Exception as parse_error:\n",
    "            print(f\"⚠️  Could not parse streaming result: {parse_error}\")\n",
    "            print(f\"📄 Raw content preview: {accumulated_content[:200]}...\")\n",
    "            print(\"💡 This is expected if the model doesn't return valid JSON in streaming mode\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Streaming test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\n🧪 Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"⚠️  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\n🧪 Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"⚠️  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\n🧪 Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"⚠️  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\n🧪 Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"⚠️  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\n🧪 Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"⚠️  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\n🧪 Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"⚠️  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: General Summarizer Agent\n",
    "# This utility agent creates summaries of various content types\n",
    "\n",
    "print(\"\\n🧪 Testing GeneralSummarizerAgent...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summarizer = GeneralSummarizerAgent(llm_service)\n",
    "\n",
    "try:\n",
    "    # Test summarization with a sample chapter\n",
    "    sample_chapter = input_story.chapters[0]  # First chapter\n",
    "    \n",
    "    # Test arc summarization with sample content\n",
    "    sample_arc_content = story_content[:15000]  # Use first part as arc content\n",
    "    arc_metadata = {\n",
    "        \"title\": \"Test Arc\",\n",
    "        \"start_chapter\": 1,\n",
    "        \"end_chapter\": 3\n",
    "    }\n",
    "    \n",
    "    summary_result = await summarizer.summarize_arc(\n",
    "        arc_content=sample_arc_content,\n",
    "        arc_metadata=arc_metadata,\n",
    "        summary_type=\"brief\",\n",
    "        user_id=TEST_USER_ID,\n",
    "        provider=TEST_PROVIDER,\n",
    "        model=TEST_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ GeneralSummarizerAgent completed successfully!\")\n",
    "    print(f\"Result type: {type(summary_result)}\")\n",
    "    print(f\"Summary result: {str(summary_result)[:500]}...\")\n",
    "    \n",
    "except NotImplementedError as e:\n",
    "    print(f\"⚠️  GeneralSummarizerAgent not yet implemented: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ GeneralSummarizerAgent failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"story_stats\": {\n",
      "    \"recommended_arcs\": 4,\n",
      "    \"arc_strategy\": \"The story was divided into four arcs based on significant shifts in location, plot, and character relationships. The first arc covers Ambertwo's rebirth and escape from the lab. The second arc focuses on her exploration of Celadon City and the reveal of Dr. Fuji's Team Rocket connections. The third arc involves the side quest with the Celadon Gym. The final arc covers the climax in Pallet Town and Ambertwo's new life with Delia and Stephen.\"\n",
      "  },\n",
      "  \"arcs\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"title\": \"Rebirth and Escape\",\n",
      "      \"start_chapter\": 1,\n",
      "      \"end_chapter\": 2,\n",
      "      \"summary\": \"Alexa dies after being hit by a truck while playing Pokemon Go and is reborn as Ambertwo, a clone of Dr. Fuji's deceased daughter Amber. She escapes the lab with Dr. Fuji and begins to adjust to the Pokemon world.\",\n",
      "      \"key_events\": \"Character dies and is reborn as Ambertwo, Dr. Fuji reveals his intentions to recreate his dead daughter, Ambertwo grapples with her new identity and the knowledge of the Pokemon world, the pair escape the underground lab and take the Pidgeot Express to Celadon City.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"title\": \"Celadon City and Team Rocket\",\n",
      "      \"start_chapter\": 3,\n",
      "      \"end_chapter\": 6,\n",
      "      \"summary\": \"Ambertwo begins to explore Celadon City and train with Ditto. She has her first Pokemon battle and is caught trespassing in the Celadon Gym greenhouse. Meanwhile, Dr. Fuji's connection to Team Rocket is revealed.\",\n",
      "      \"key_events\": \"Ambertwo explores Celadon City, battles Joey, and is caught trespassing in the Celadon Gym greenhouse. Dr. Fuji's activities with Team Rocket are revealed as he attempts to find his wife.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"title\": \"The Great Oddish Heist\",\n",
      "      \"start_chapter\": 7,\n",
      "      \"end_chapter\": 10,\n",
      "      \"summary\": \"Ambertwo and Mary investigate a theft at the Celadon Gym, leading them to a girl trying to save her sick brother. They enlist Erika's help and resolve the situation. Dr. Fuji reclaims Ditto and punishes Ambertwo, setting the stage for a new direction in the story.\",\n",
      "      \"key_events\": \"Ambertwo and Mary investigate a theft at the Celadon Gym, befriend Erika, and help a sick child. Dr. Fuji reclaims Ditto and punishes Ambertwo.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"title\": \"Pallet Town and the Final Confrontation\",\n",
      "      \"start_chapter\": 11,\n",
      "      \"end_chapter\": 17,\n",
      "      \"summary\": \"Dr. Fuji takes Ambertwo to Pallet Town, where he confronts Delia and Stephen. He attacks Stephen and Delia's home, leading to a battle with Professor Oak and his subsequent arrest. Ambertwo is left in the care of Delia and Stephen, beginning a new chapter in her life.\",\n",
      "      \"key_events\": \"Dr. Fuji takes Ambertwo to Pallet Town and attempts to force her into his idealized version of their family, leading to a confrontation with Delia and Stephen. Dr. Fuji attacks Stephen and Delia's home, resulting in a battle with Professor Oak and his subsequent arrest. Ambertwo is left in the care of Delia and Stephen.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(final_result.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiPlanner Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArticleWriterAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneralSummarizerAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiGenOrchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
